{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Romanos NN\n",
    "Neste notebook vamos treinar uma *Rede Neural* simples para converter números para algarismos romanos.\n",
    "\n",
    "## Dataset\n",
    "O dataset é uma tabela contendo **4999** algarismos romanos e seu correspondente em algarismos indo-arábicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero</th>\n",
       "      <th>romano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numero romano\n",
       "0       1      I\n",
       "1       2     II\n",
       "2       3    III\n",
       "3       4     IV\n",
       "4       5      V"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"romanos.csv\", sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero</th>\n",
       "      <th>romano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>4995</td>\n",
       "      <td>MMMMCMXCV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4996</td>\n",
       "      <td>MMMMCMXCVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4997</td>\n",
       "      <td>MMMMCMXCVII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4998</td>\n",
       "      <td>MMMMCMXCVIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4999</td>\n",
       "      <td>MMMMCMXCIX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      numero        romano\n",
       "4994    4995     MMMMCMXCV\n",
       "4995    4996    MMMMCMXCVI\n",
       "4996    4997   MMMMCMXCVII\n",
       "4997    4998  MMMMCMXCVIII\n",
       "4998    4999    MMMMCMXCIX"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos dados\n",
    "O primeiro passo para treinar uma rede neural é a preparação de dados. Vamos criar `encodings` para a entrada e a saída dos dados.\n",
    "\n",
    "A entrada de dados será uma array contendo o valor de cada número em binário (13 bits).\n",
    "\n",
    "A saída de dados será uma array de 16 bytes contendo a string de saída (128 bits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero                4888\n",
       "romano    MMMMDCCCLXXXVIII\n",
       "Name: 4887, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"romano\"].apply(len).sort_values(ascending=False).index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero</th>\n",
       "      <th>romano</th>\n",
       "      <th>in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>II</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>III</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>IV</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>V</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numero romano                                       in\n",
       "0       1      I  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
       "1       2     II  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
       "2       3    III  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
       "3       4     IV  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
       "4       5      V  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_in(row):\n",
    "    R = [int(x) for x in bin(row)[2:]]\n",
    "    R = [0] * (13 - len(R)) + R\n",
    "    return R\n",
    "    \n",
    "df[\"in\"] = df[\"numero\"].apply(encode_in)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_in(row):\n",
    "    return int(\"\".join([str(x) for x in row]), base=2)\n",
    "    \n",
    "df[\"in\"].apply(decode_in)\n",
    "df[\"in\"].apply(decode_in) == df[\"numero\"]\n",
    "all(df[\"in\"].apply(decode_in) == df[\"numero\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero</th>\n",
       "      <th>romano</th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>II</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>III</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>IV</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>V</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numero romano                                       in  \\\n",
       "0       1      I  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "1       2     II  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
       "2       3    III  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]   \n",
       "3       4     IV  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "4       5      V  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]   \n",
       "\n",
       "                                                 out  \n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_out(row):\n",
    "    numerais = [\"I\", \"V\", \"X\", \"L\", \"C\", \"D\", \"M\", \" \"]\n",
    "    zeros = np.zeros((16, len(numerais))).astype(np.uint8)\n",
    "    R = list(row)\n",
    "    R = [numerais.index(letra) for letra in R]\n",
    "    R += [len(numerais)-1] * (16 - len(R))\n",
    "    zeros[np.arange(16), R] = 1\n",
    "    return zeros.flatten()\n",
    "    \n",
    "df[\"out\"] = df[\"romano\"].apply(encode_out)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_out(row):\n",
    "    numerais = [\"I\", \"V\", \"X\", \"L\", \"C\", \"D\", \"M\", \" \"]\n",
    "    return \"\".join([numerais[i] for i in row.reshape((16, -1)).argmax(axis=1)]).strip()\n",
    "\n",
    "df[\"out\"].apply(decode_out)\n",
    "df[\"out\"].apply(decode_out) == df[\"romano\"]\n",
    "all(df[\"out\"].apply(decode_out) == df[\"romano\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a preparação dos dados, vamos dividir o dataset em dois conjuntos, o conjunto de treino contendo 80% dos dados e o conjunto de teste contendo 20% dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treino: 3999 teste: 1000\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "df_train = df_train.reset_index().drop(columns=\"index\")\n",
    "df_test = df_test.reset_index().drop(columns=\"index\")\n",
    "print(\"treino:\", len(df_train), \"teste:\", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conjunto de treino: 3999 linhas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero</th>\n",
       "      <th>romano</th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>884</td>\n",
       "      <td>DCCCLXXXIV</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>344</td>\n",
       "      <td>CCCXLIV</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2500</td>\n",
       "      <td>MMD</td>\n",
       "      <td>[0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1770</td>\n",
       "      <td>MDCCLXX</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3958</td>\n",
       "      <td>MMMCMLVIII</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numero      romano                                       in  \\\n",
       "0     884  DCCCLXXXIV  [0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0]   \n",
       "1     344     CCCXLIV  [0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0]   \n",
       "2    2500         MMD  [0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0]   \n",
       "3    1770     MDCCLXX  [0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0]   \n",
       "4    3958  MMMCMLVIII  [0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]   \n",
       "\n",
       "                                                 out  \n",
       "0  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"conjunto de treino: {} linhas\".format(len(df_train)))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conjunto de teste: 1000 linhas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero</th>\n",
       "      <th>romano</th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3208</td>\n",
       "      <td>MMMCCVIII</td>\n",
       "      <td>[0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4994</td>\n",
       "      <td>MMMMCMXCIV</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3997</td>\n",
       "      <td>MMMCMXCVII</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2573</td>\n",
       "      <td>MMDLXXIII</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4184</td>\n",
       "      <td>MMMMCLXXXIV</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numero       romano                                       in  \\\n",
       "0    3208    MMMCCVIII  [0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]   \n",
       "1    4994   MMMMCMXCIV  [1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0]   \n",
       "2    3997   MMMCMXCVII  [0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1]   \n",
       "3    2573    MMDLXXIII  [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1]   \n",
       "4    4184  MMMMCLXXXIV  [1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]   \n",
       "\n",
       "                                                 out  \n",
       "0  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"conjunto de teste: {} linhas\".format(len(df_test)))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importante\n",
    "- Extrair as características dos dados de entrada e saída;\n",
    "- Separar os conjuntos de treino e de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "As redes neurais realizam apenas três operações muito simples: \n",
    "  - MatMul;\n",
    "  - Bias Add;\n",
    "  - ACTIVATE!!!\n",
    "  \n",
    "![rede neural](Colored_neural_network.svg)\n",
    "\n",
    "\\begin{align}\n",
    "\\text{MatMul: }& h = W^t\\cdotp X \\\\\n",
    "\\text{Bias Add: }& Z = W^t\\cdotp X + b\\\\\n",
    "\\text{ACTIVATE!: }& A = f(W^t\\cdotp X + b)\\\\\n",
    "\\end{align}\n",
    "\n",
    "Para treinar uma rede, podemos comparar a saída da rede com a saída esperada e ajustar os pesos da matriz ***W*** e do vetor ***b*** de acordo com os erros. A técnica mais utilizada para isso é o **Backpropagation**.\n",
    "\n",
    "Além disso, existem *otimizadores* que ajudam a manter a estabilidade do treino, além de diminuir o tempo necessário. Utilizaremos o **Adam** que ajusta alguns hiperparâmetros da rede automaticamente.\n",
    "\n",
    "![adam](adam.png)\n",
    "\n",
    "Com os dados prontos, podemos treinar as redes neurais. Vamos começar com uma rede pequena com apenas uma camada oculta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "=================================================================\n",
      "Total params: 9,216\n",
      "Trainable params: 9,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=13))\n",
    "model.add(Dense(units=128, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rede neural inicialmente \"chuta\" qualquer valor para a saída (acurácia ~50%). O texto gerado é aleatório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "Custo: 0.7031677951812744\n",
      "Acurácia: 0.498171875\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, df):\n",
    "    res = model.evaluate(np.array(df[\"in\"].values.tolist()), np.array(df[\"out\"].values.tolist()))\n",
    "    print(\"Custo: {}\\nAcurácia: {}\".format(*res))\n",
    "evaluate_model(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acertos 0.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>numero</th>\n",
       "      <th>pred</th>\n",
       "      <th>romano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3208</td>\n",
       "      <td>VDLDLCV CLX MCVC</td>\n",
       "      <td>MMMCCVIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>4994</td>\n",
       "      <td>VDVVLMV  IX XIVD</td>\n",
       "      <td>MMMMCMXCIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3997</td>\n",
       "      <td>VDLLCMVCL XXXVVM</td>\n",
       "      <td>MMMCMXCVII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>2573</td>\n",
       "      <td>LX LCMVI  CX VMD</td>\n",
       "      <td>MMDLXXIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>4184</td>\n",
       "      <td>VLVLLCVC LIDVVVD</td>\n",
       "      <td>MMMMCLXXXIV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match  numero              pred       romano\n",
       "0  False    3208  VDLDLCV CLX MCVC    MMMCCVIII\n",
       "1  False    4994  VDVVLMV  IX XIVD   MMMMCMXCIV\n",
       "2  False    3997  VDLLCMVCL XXXVVM   MMMCMXCVII\n",
       "3  False    2573  LX LCMVI  CX VMD    MMDLXXIII\n",
       "4  False    4184  VLVLLCVC LIDVVVD  MMMMCLXXXIV"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_predictions(model, df):\n",
    "    pred = model.predict(np.array(df[\"in\"].values.tolist()))\n",
    "    data = []\n",
    "    for (_, row), p in zip(df.iterrows(), pred):\n",
    "        _p = decode_out(p)\n",
    "        data.append({\n",
    "            \"numero\": row[\"numero\"],\n",
    "            \"romano\": row[\"romano\"],\n",
    "            \"pred\": _p,\n",
    "            \"match\": row[\"romano\"] == _p\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "def evaluate_algorisms(model, df):\n",
    "    _df = make_predictions(model, df)\n",
    "    acertos = _df[\"match\"].sum()\n",
    "    print(acertos, \"acertos\", round(acertos/len(_df)*100, 2), \"%\")\n",
    "    return _df\n",
    "\n",
    "df_p0 = evaluate_algorisms(model, df_test)\n",
    "df_p0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando o modelo por uma época (todos os ~3999 algarismos) começamos a ver resultados mais coerentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3599 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "3599/3599 [==============================] - 0s 94us/step - loss: 0.3874 - acc: 0.8669 - val_loss: 0.2048 - val_acc: 0.9292\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(df_train[\"in\"].values.tolist()), np.array(df_train[\"out\"].values.tolist()), epochs=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 24us/step\n",
      "Custo: 0.2024269211292267\n",
      "Acurácia: 0.929890625\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acertos 0.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>numero</th>\n",
       "      <th>pred</th>\n",
       "      <th>romano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3208</td>\n",
       "      <td>MMMCCXX</td>\n",
       "      <td>MMMCCVIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>4994</td>\n",
       "      <td>MMMMXCX</td>\n",
       "      <td>MMMMCMXCIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3997</td>\n",
       "      <td>MMMCCXX</td>\n",
       "      <td>MMMCMXCVII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>2573</td>\n",
       "      <td>MMMCCXXI</td>\n",
       "      <td>MMDLXXIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>4184</td>\n",
       "      <td>MMMMXC</td>\n",
       "      <td>MMMMCLXXXIV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match  numero      pred       romano\n",
       "0  False    3208   MMMCCXX    MMMCCVIII\n",
       "1  False    4994   MMMMXCX   MMMMCMXCIV\n",
       "2  False    3997   MMMCCXX   MMMCMXCVII\n",
       "3  False    2573  MMMCCXXI    MMDLXXIII\n",
       "4  False    4184    MMMMXC  MMMMCLXXXIV"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p1 = evaluate_algorisms(model, df_test)\n",
    "df_p1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Underfit!!!\n",
    "Neste caso, o modelo entende a estrutura geral da saída (não separar os algarismos por exemplo), mas ainda não consegue prever os valores corretamente. Dizemos que esse modelo tem um grande viés, e está em regime de **underfit**.\n",
    "\n",
    "\n",
    "## Treinando mais épocas\n",
    "Vamos treinar o mesmo modelo por mais 499 épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3599 samples, validate on 400 samples\n",
      "Epoch 1/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.1871 - acc: 0.9329 - val_loss: 0.1834 - val_acc: 0.9337\n",
      "Epoch 2/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.1731 - acc: 0.9373 - val_loss: 0.1717 - val_acc: 0.9371\n",
      "Epoch 3/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.1629 - acc: 0.9397 - val_loss: 0.1623 - val_acc: 0.9395\n",
      "Epoch 4/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.1553 - acc: 0.9411 - val_loss: 0.1561 - val_acc: 0.9399\n",
      "Epoch 5/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.1500 - acc: 0.9417 - val_loss: 0.1518 - val_acc: 0.9406\n",
      "Epoch 6/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.1463 - acc: 0.9421 - val_loss: 0.1483 - val_acc: 0.9413\n",
      "Epoch 7/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.1434 - acc: 0.9427 - val_loss: 0.1458 - val_acc: 0.9415\n",
      "Epoch 8/499\n",
      "3599/3599 [==============================] - 0s 74us/step - loss: 0.1410 - acc: 0.9433 - val_loss: 0.1433 - val_acc: 0.9426\n",
      "Epoch 9/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.1390 - acc: 0.9440 - val_loss: 0.1415 - val_acc: 0.9432\n",
      "Epoch 10/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.1373 - acc: 0.9442 - val_loss: 0.1397 - val_acc: 0.9433\n",
      "Epoch 11/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.1358 - acc: 0.9445 - val_loss: 0.1379 - val_acc: 0.9441\n",
      "Epoch 12/499\n",
      "3599/3599 [==============================] - 0s 75us/step - loss: 0.1346 - acc: 0.9448 - val_loss: 0.1371 - val_acc: 0.9443\n",
      "Epoch 13/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.1334 - acc: 0.9451 - val_loss: 0.1361 - val_acc: 0.9444\n",
      "Epoch 14/499\n",
      "3599/3599 [==============================] - 0s 88us/step - loss: 0.1325 - acc: 0.9452 - val_loss: 0.1347 - val_acc: 0.9448\n",
      "Epoch 15/499\n",
      "3599/3599 [==============================] - 0s 94us/step - loss: 0.1315 - acc: 0.9455 - val_loss: 0.1338 - val_acc: 0.9447\n",
      "Epoch 16/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.1308 - acc: 0.9456 - val_loss: 0.1332 - val_acc: 0.9454\n",
      "Epoch 17/499\n",
      "3599/3599 [==============================] - 0s 81us/step - loss: 0.1299 - acc: 0.9458 - val_loss: 0.1328 - val_acc: 0.9452\n",
      "Epoch 18/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.1292 - acc: 0.9461 - val_loss: 0.1323 - val_acc: 0.9457\n",
      "Epoch 19/499\n",
      "3599/3599 [==============================] - 0s 87us/step - loss: 0.1285 - acc: 0.9465 - val_loss: 0.1311 - val_acc: 0.9459\n",
      "Epoch 20/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.1279 - acc: 0.9467 - val_loss: 0.1306 - val_acc: 0.9464\n",
      "Epoch 21/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.1272 - acc: 0.9469 - val_loss: 0.1299 - val_acc: 0.9457\n",
      "Epoch 22/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.1265 - acc: 0.9472 - val_loss: 0.1291 - val_acc: 0.9465\n",
      "Epoch 23/499\n",
      "3599/3599 [==============================] - 0s 86us/step - loss: 0.1259 - acc: 0.9474 - val_loss: 0.1285 - val_acc: 0.9465\n",
      "Epoch 24/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.1253 - acc: 0.9476 - val_loss: 0.1278 - val_acc: 0.9466\n",
      "Epoch 25/499\n",
      "3599/3599 [==============================] - 0s 80us/step - loss: 0.1246 - acc: 0.9480 - val_loss: 0.1274 - val_acc: 0.9471\n",
      "Epoch 26/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.1240 - acc: 0.9482 - val_loss: 0.1267 - val_acc: 0.9471\n",
      "Epoch 27/499\n",
      "3599/3599 [==============================] - 0s 78us/step - loss: 0.1233 - acc: 0.9485 - val_loss: 0.1265 - val_acc: 0.9473\n",
      "Epoch 28/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.1227 - acc: 0.9489 - val_loss: 0.1256 - val_acc: 0.9478\n",
      "Epoch 29/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.1221 - acc: 0.9490 - val_loss: 0.1249 - val_acc: 0.9480\n",
      "Epoch 30/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.1215 - acc: 0.9494 - val_loss: 0.1247 - val_acc: 0.9481\n",
      "Epoch 31/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.1208 - acc: 0.9496 - val_loss: 0.1240 - val_acc: 0.9488\n",
      "Epoch 32/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.1202 - acc: 0.9501 - val_loss: 0.1237 - val_acc: 0.9486\n",
      "Epoch 33/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.1196 - acc: 0.9503 - val_loss: 0.1231 - val_acc: 0.9492\n",
      "Epoch 34/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.1190 - acc: 0.9505 - val_loss: 0.1225 - val_acc: 0.9497\n",
      "Epoch 35/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.1184 - acc: 0.9511 - val_loss: 0.1219 - val_acc: 0.9495\n",
      "Epoch 36/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.1178 - acc: 0.9513 - val_loss: 0.1215 - val_acc: 0.9500\n",
      "Epoch 37/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.1172 - acc: 0.9515 - val_loss: 0.1208 - val_acc: 0.9500\n",
      "Epoch 38/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.1166 - acc: 0.9517 - val_loss: 0.1204 - val_acc: 0.9506\n",
      "Epoch 39/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.1161 - acc: 0.9520 - val_loss: 0.1197 - val_acc: 0.9506\n",
      "Epoch 40/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.1154 - acc: 0.9523 - val_loss: 0.1194 - val_acc: 0.9507\n",
      "Epoch 41/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.1150 - acc: 0.9522 - val_loss: 0.1189 - val_acc: 0.9511\n",
      "Epoch 42/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.1143 - acc: 0.9526 - val_loss: 0.1183 - val_acc: 0.9510\n",
      "Epoch 43/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.1138 - acc: 0.9529 - val_loss: 0.1177 - val_acc: 0.9511\n",
      "Epoch 44/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.1133 - acc: 0.9529 - val_loss: 0.1172 - val_acc: 0.9515\n",
      "Epoch 45/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.1127 - acc: 0.9532 - val_loss: 0.1168 - val_acc: 0.9519\n",
      "Epoch 46/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.1122 - acc: 0.9532 - val_loss: 0.1164 - val_acc: 0.9518\n",
      "Epoch 47/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.1116 - acc: 0.9536 - val_loss: 0.1159 - val_acc: 0.9522\n",
      "Epoch 48/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.1112 - acc: 0.9538 - val_loss: 0.1152 - val_acc: 0.9523\n",
      "Epoch 49/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.1107 - acc: 0.9539 - val_loss: 0.1149 - val_acc: 0.9524\n",
      "Epoch 50/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.1103 - acc: 0.9540 - val_loss: 0.1144 - val_acc: 0.9525\n",
      "Epoch 51/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.1098 - acc: 0.9542 - val_loss: 0.1141 - val_acc: 0.9530\n",
      "Epoch 52/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.1094 - acc: 0.9545 - val_loss: 0.1135 - val_acc: 0.9532\n",
      "Epoch 53/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.1089 - acc: 0.9546 - val_loss: 0.1133 - val_acc: 0.9532\n",
      "Epoch 54/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.1085 - acc: 0.9548 - val_loss: 0.1130 - val_acc: 0.9534\n",
      "Epoch 55/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.1080 - acc: 0.9552 - val_loss: 0.1126 - val_acc: 0.9537\n",
      "Epoch 56/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.1077 - acc: 0.9552 - val_loss: 0.1121 - val_acc: 0.9538\n",
      "Epoch 57/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.1073 - acc: 0.9554 - val_loss: 0.1116 - val_acc: 0.9542\n",
      "Epoch 58/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.1069 - acc: 0.9556 - val_loss: 0.1115 - val_acc: 0.9544\n",
      "Epoch 59/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.1065 - acc: 0.9559 - val_loss: 0.1113 - val_acc: 0.9546\n",
      "Epoch 60/499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.1061 - acc: 0.9561 - val_loss: 0.1106 - val_acc: 0.9545\n",
      "Epoch 61/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.1058 - acc: 0.9561 - val_loss: 0.1103 - val_acc: 0.9552\n",
      "Epoch 62/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.1054 - acc: 0.9564 - val_loss: 0.1102 - val_acc: 0.9547\n",
      "Epoch 63/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.1051 - acc: 0.9566 - val_loss: 0.1098 - val_acc: 0.9549\n",
      "Epoch 64/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.1047 - acc: 0.9567 - val_loss: 0.1096 - val_acc: 0.9551\n",
      "Epoch 65/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.1044 - acc: 0.9567 - val_loss: 0.1093 - val_acc: 0.9555\n",
      "Epoch 66/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.1041 - acc: 0.9569 - val_loss: 0.1090 - val_acc: 0.9555\n",
      "Epoch 67/499\n",
      "3599/3599 [==============================] - 0s 58us/step - loss: 0.1037 - acc: 0.9570 - val_loss: 0.1086 - val_acc: 0.9555\n",
      "Epoch 68/499\n",
      "3599/3599 [==============================] - 0s 58us/step - loss: 0.1035 - acc: 0.9572 - val_loss: 0.1084 - val_acc: 0.9555\n",
      "Epoch 69/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.1031 - acc: 0.9574 - val_loss: 0.1082 - val_acc: 0.9558\n",
      "Epoch 70/499\n",
      "3599/3599 [==============================] - 0s 58us/step - loss: 0.1028 - acc: 0.9574 - val_loss: 0.1080 - val_acc: 0.9560\n",
      "Epoch 71/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.1025 - acc: 0.9576 - val_loss: 0.1077 - val_acc: 0.9558\n",
      "Epoch 72/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.1023 - acc: 0.9576 - val_loss: 0.1072 - val_acc: 0.9560\n",
      "Epoch 73/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.1020 - acc: 0.9579 - val_loss: 0.1070 - val_acc: 0.9563\n",
      "Epoch 74/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.1017 - acc: 0.9581 - val_loss: 0.1068 - val_acc: 0.9562\n",
      "Epoch 75/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.1015 - acc: 0.9582 - val_loss: 0.1068 - val_acc: 0.9564\n",
      "Epoch 76/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.1012 - acc: 0.9581 - val_loss: 0.1064 - val_acc: 0.9564\n",
      "Epoch 77/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.1009 - acc: 0.9583 - val_loss: 0.1064 - val_acc: 0.9565\n",
      "Epoch 78/499\n",
      "3599/3599 [==============================] - 0s 58us/step - loss: 0.1006 - acc: 0.9584 - val_loss: 0.1061 - val_acc: 0.9565\n",
      "Epoch 79/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.1004 - acc: 0.9585 - val_loss: 0.1058 - val_acc: 0.9566\n",
      "Epoch 80/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.1001 - acc: 0.9587 - val_loss: 0.1058 - val_acc: 0.9565\n",
      "Epoch 81/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0999 - acc: 0.9586 - val_loss: 0.1055 - val_acc: 0.9566\n",
      "Epoch 82/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0997 - acc: 0.9589 - val_loss: 0.1054 - val_acc: 0.9567\n",
      "Epoch 83/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0994 - acc: 0.9590 - val_loss: 0.1050 - val_acc: 0.9566\n",
      "Epoch 84/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0992 - acc: 0.9591 - val_loss: 0.1048 - val_acc: 0.9568\n",
      "Epoch 85/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.0990 - acc: 0.9591 - val_loss: 0.1047 - val_acc: 0.9570\n",
      "Epoch 86/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0988 - acc: 0.9592 - val_loss: 0.1046 - val_acc: 0.9570\n",
      "Epoch 87/499\n",
      "3599/3599 [==============================] - 0s 74us/step - loss: 0.0985 - acc: 0.9592 - val_loss: 0.1043 - val_acc: 0.9570\n",
      "Epoch 88/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.0983 - acc: 0.9595 - val_loss: 0.1043 - val_acc: 0.9573\n",
      "Epoch 89/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0981 - acc: 0.9594 - val_loss: 0.1038 - val_acc: 0.9575\n",
      "Epoch 90/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0979 - acc: 0.9596 - val_loss: 0.1037 - val_acc: 0.9572\n",
      "Epoch 91/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0977 - acc: 0.9595 - val_loss: 0.1036 - val_acc: 0.9574\n",
      "Epoch 92/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0975 - acc: 0.9597 - val_loss: 0.1036 - val_acc: 0.9576\n",
      "Epoch 93/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0973 - acc: 0.9597 - val_loss: 0.1032 - val_acc: 0.9574\n",
      "Epoch 94/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0971 - acc: 0.9598 - val_loss: 0.1031 - val_acc: 0.9572\n",
      "Epoch 95/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0969 - acc: 0.9598 - val_loss: 0.1029 - val_acc: 0.9577\n",
      "Epoch 96/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0967 - acc: 0.9600 - val_loss: 0.1027 - val_acc: 0.9574\n",
      "Epoch 97/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0965 - acc: 0.9600 - val_loss: 0.1026 - val_acc: 0.9577\n",
      "Epoch 98/499\n",
      "3599/3599 [==============================] - 0s 58us/step - loss: 0.0963 - acc: 0.9600 - val_loss: 0.1023 - val_acc: 0.9577\n",
      "Epoch 99/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0960 - acc: 0.9602 - val_loss: 0.1022 - val_acc: 0.9579\n",
      "Epoch 100/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0958 - acc: 0.9603 - val_loss: 0.1020 - val_acc: 0.9577\n",
      "Epoch 101/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0957 - acc: 0.9605 - val_loss: 0.1018 - val_acc: 0.9574\n",
      "Epoch 102/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0955 - acc: 0.9604 - val_loss: 0.1016 - val_acc: 0.9582\n",
      "Epoch 103/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0953 - acc: 0.9605 - val_loss: 0.1014 - val_acc: 0.9578\n",
      "Epoch 104/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0951 - acc: 0.9606 - val_loss: 0.1015 - val_acc: 0.9584\n",
      "Epoch 105/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0949 - acc: 0.9607 - val_loss: 0.1014 - val_acc: 0.9578\n",
      "Epoch 106/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0947 - acc: 0.9608 - val_loss: 0.1009 - val_acc: 0.9581\n",
      "Epoch 107/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0945 - acc: 0.9609 - val_loss: 0.1005 - val_acc: 0.9585\n",
      "Epoch 108/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0943 - acc: 0.9610 - val_loss: 0.1006 - val_acc: 0.9587\n",
      "Epoch 109/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0941 - acc: 0.9611 - val_loss: 0.1004 - val_acc: 0.9585\n",
      "Epoch 110/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0939 - acc: 0.9611 - val_loss: 0.1000 - val_acc: 0.9587\n",
      "Epoch 111/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0937 - acc: 0.9612 - val_loss: 0.1000 - val_acc: 0.9588\n",
      "Epoch 112/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0935 - acc: 0.9612 - val_loss: 0.0999 - val_acc: 0.9587\n",
      "Epoch 113/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0933 - acc: 0.9614 - val_loss: 0.0994 - val_acc: 0.9588\n",
      "Epoch 114/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0931 - acc: 0.9615 - val_loss: 0.0994 - val_acc: 0.9587\n",
      "Epoch 115/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0929 - acc: 0.9616 - val_loss: 0.0991 - val_acc: 0.9591\n",
      "Epoch 116/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0927 - acc: 0.9618 - val_loss: 0.0989 - val_acc: 0.9594\n",
      "Epoch 117/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0925 - acc: 0.9619 - val_loss: 0.0989 - val_acc: 0.9588\n",
      "Epoch 118/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0923 - acc: 0.9619 - val_loss: 0.0988 - val_acc: 0.9593\n",
      "Epoch 119/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0921 - acc: 0.9620 - val_loss: 0.0984 - val_acc: 0.9595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/499\n",
      "3599/3599 [==============================] - 0s 58us/step - loss: 0.0920 - acc: 0.9619 - val_loss: 0.0982 - val_acc: 0.9597\n",
      "Epoch 121/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0918 - acc: 0.9621 - val_loss: 0.0981 - val_acc: 0.9595\n",
      "Epoch 122/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0916 - acc: 0.9622 - val_loss: 0.0977 - val_acc: 0.9596\n",
      "Epoch 123/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0914 - acc: 0.9622 - val_loss: 0.0978 - val_acc: 0.9598\n",
      "Epoch 124/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0912 - acc: 0.9622 - val_loss: 0.0976 - val_acc: 0.9599\n",
      "Epoch 125/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0910 - acc: 0.9625 - val_loss: 0.0975 - val_acc: 0.9596\n",
      "Epoch 126/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0909 - acc: 0.9625 - val_loss: 0.0971 - val_acc: 0.9603\n",
      "Epoch 127/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0907 - acc: 0.9626 - val_loss: 0.0971 - val_acc: 0.9603\n",
      "Epoch 128/499\n",
      "3599/3599 [==============================] - 0s 58us/step - loss: 0.0905 - acc: 0.9625 - val_loss: 0.0968 - val_acc: 0.9600\n",
      "Epoch 129/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0903 - acc: 0.9628 - val_loss: 0.0968 - val_acc: 0.9601\n",
      "Epoch 130/499\n",
      "3599/3599 [==============================] - 0s 58us/step - loss: 0.0902 - acc: 0.9626 - val_loss: 0.0966 - val_acc: 0.9602\n",
      "Epoch 131/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0900 - acc: 0.9628 - val_loss: 0.0964 - val_acc: 0.9604\n",
      "Epoch 132/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0898 - acc: 0.9629 - val_loss: 0.0968 - val_acc: 0.9603\n",
      "Epoch 133/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0897 - acc: 0.9629 - val_loss: 0.0962 - val_acc: 0.9606\n",
      "Epoch 134/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0896 - acc: 0.9631 - val_loss: 0.0961 - val_acc: 0.9606\n",
      "Epoch 135/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0894 - acc: 0.9630 - val_loss: 0.0961 - val_acc: 0.9605\n",
      "Epoch 136/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0892 - acc: 0.9632 - val_loss: 0.0957 - val_acc: 0.9605\n",
      "Epoch 137/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0891 - acc: 0.9632 - val_loss: 0.0957 - val_acc: 0.9606\n",
      "Epoch 138/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.0889 - acc: 0.9633 - val_loss: 0.0953 - val_acc: 0.9608\n",
      "Epoch 139/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.0888 - acc: 0.9633 - val_loss: 0.0952 - val_acc: 0.9606\n",
      "Epoch 140/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0887 - acc: 0.9633 - val_loss: 0.0951 - val_acc: 0.9608\n",
      "Epoch 141/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0885 - acc: 0.9636 - val_loss: 0.0954 - val_acc: 0.9609\n",
      "Epoch 142/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0884 - acc: 0.9633 - val_loss: 0.0950 - val_acc: 0.9613\n",
      "Epoch 143/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0883 - acc: 0.9636 - val_loss: 0.0948 - val_acc: 0.9614\n",
      "Epoch 144/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0882 - acc: 0.9636 - val_loss: 0.0946 - val_acc: 0.9610\n",
      "Epoch 145/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0880 - acc: 0.9635 - val_loss: 0.0950 - val_acc: 0.9613\n",
      "Epoch 146/499\n",
      "3599/3599 [==============================] - 0s 80us/step - loss: 0.0878 - acc: 0.9638 - val_loss: 0.0943 - val_acc: 0.9610\n",
      "Epoch 147/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0877 - acc: 0.9636 - val_loss: 0.0942 - val_acc: 0.9613\n",
      "Epoch 148/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.0876 - acc: 0.9637 - val_loss: 0.0941 - val_acc: 0.9618\n",
      "Epoch 149/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0874 - acc: 0.9639 - val_loss: 0.0939 - val_acc: 0.9613\n",
      "Epoch 150/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0873 - acc: 0.9638 - val_loss: 0.0939 - val_acc: 0.9614\n",
      "Epoch 151/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0872 - acc: 0.9639 - val_loss: 0.0939 - val_acc: 0.9615\n",
      "Epoch 152/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0871 - acc: 0.9639 - val_loss: 0.0936 - val_acc: 0.9618\n",
      "Epoch 153/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.0870 - acc: 0.9640 - val_loss: 0.0936 - val_acc: 0.9616\n",
      "Epoch 154/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0868 - acc: 0.9640 - val_loss: 0.0935 - val_acc: 0.9618\n",
      "Epoch 155/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0867 - acc: 0.9641 - val_loss: 0.0933 - val_acc: 0.9617\n",
      "Epoch 156/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0866 - acc: 0.9641 - val_loss: 0.0935 - val_acc: 0.9621\n",
      "Epoch 157/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0865 - acc: 0.9641 - val_loss: 0.0931 - val_acc: 0.9620\n",
      "Epoch 158/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0863 - acc: 0.9643 - val_loss: 0.0930 - val_acc: 0.9618\n",
      "Epoch 159/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0862 - acc: 0.9643 - val_loss: 0.0933 - val_acc: 0.9620\n",
      "Epoch 160/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0861 - acc: 0.9643 - val_loss: 0.0929 - val_acc: 0.9622\n",
      "Epoch 161/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0860 - acc: 0.9643 - val_loss: 0.0929 - val_acc: 0.9623\n",
      "Epoch 162/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.0860 - acc: 0.9643 - val_loss: 0.0927 - val_acc: 0.9621\n",
      "Epoch 163/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0858 - acc: 0.9644 - val_loss: 0.0924 - val_acc: 0.9624\n",
      "Epoch 164/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0857 - acc: 0.9646 - val_loss: 0.0924 - val_acc: 0.9624\n",
      "Epoch 165/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0855 - acc: 0.9646 - val_loss: 0.0923 - val_acc: 0.9626\n",
      "Epoch 166/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0855 - acc: 0.9646 - val_loss: 0.0924 - val_acc: 0.9622\n",
      "Epoch 167/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.0854 - acc: 0.9646 - val_loss: 0.0922 - val_acc: 0.9625\n",
      "Epoch 168/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0854 - acc: 0.9646 - val_loss: 0.0921 - val_acc: 0.9622\n",
      "Epoch 169/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.0852 - acc: 0.9647 - val_loss: 0.0917 - val_acc: 0.9628\n",
      "Epoch 170/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0850 - acc: 0.9646 - val_loss: 0.0919 - val_acc: 0.9625\n",
      "Epoch 171/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0849 - acc: 0.9648 - val_loss: 0.0917 - val_acc: 0.9626\n",
      "Epoch 172/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0849 - acc: 0.9649 - val_loss: 0.0916 - val_acc: 0.9629\n",
      "Epoch 173/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.0847 - acc: 0.9649 - val_loss: 0.0916 - val_acc: 0.9630\n",
      "Epoch 174/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.0846 - acc: 0.9649 - val_loss: 0.0914 - val_acc: 0.9627\n",
      "Epoch 175/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0846 - acc: 0.9650 - val_loss: 0.0915 - val_acc: 0.9627\n",
      "Epoch 176/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0844 - acc: 0.9650 - val_loss: 0.0913 - val_acc: 0.9632\n",
      "Epoch 177/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.0843 - acc: 0.9651 - val_loss: 0.0912 - val_acc: 0.9631\n",
      "Epoch 178/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.0843 - acc: 0.9652 - val_loss: 0.0910 - val_acc: 0.9628\n",
      "Epoch 179/499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.0841 - acc: 0.9652 - val_loss: 0.0907 - val_acc: 0.9631\n",
      "Epoch 180/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0840 - acc: 0.9652 - val_loss: 0.0909 - val_acc: 0.9630\n",
      "Epoch 181/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0840 - acc: 0.9653 - val_loss: 0.0909 - val_acc: 0.9630\n",
      "Epoch 182/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0838 - acc: 0.9654 - val_loss: 0.0909 - val_acc: 0.9630\n",
      "Epoch 183/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0838 - acc: 0.9652 - val_loss: 0.0908 - val_acc: 0.9632\n",
      "Epoch 184/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0836 - acc: 0.9655 - val_loss: 0.0907 - val_acc: 0.9631\n",
      "Epoch 185/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0835 - acc: 0.9655 - val_loss: 0.0905 - val_acc: 0.9632\n",
      "Epoch 186/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.0834 - acc: 0.9654 - val_loss: 0.0905 - val_acc: 0.9631\n",
      "Epoch 187/499\n",
      "3599/3599 [==============================] - 0s 78us/step - loss: 0.0834 - acc: 0.9654 - val_loss: 0.0904 - val_acc: 0.9632\n",
      "Epoch 188/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0833 - acc: 0.9656 - val_loss: 0.0903 - val_acc: 0.9635\n",
      "Epoch 189/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0832 - acc: 0.9655 - val_loss: 0.0903 - val_acc: 0.9631\n",
      "Epoch 190/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0831 - acc: 0.9656 - val_loss: 0.0900 - val_acc: 0.9633\n",
      "Epoch 191/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0830 - acc: 0.9656 - val_loss: 0.0899 - val_acc: 0.9635\n",
      "Epoch 192/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0829 - acc: 0.9657 - val_loss: 0.0902 - val_acc: 0.9634\n",
      "Epoch 193/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0829 - acc: 0.9658 - val_loss: 0.0898 - val_acc: 0.9634\n",
      "Epoch 194/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0828 - acc: 0.9657 - val_loss: 0.0897 - val_acc: 0.9634\n",
      "Epoch 195/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0826 - acc: 0.9658 - val_loss: 0.0897 - val_acc: 0.9638\n",
      "Epoch 196/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0825 - acc: 0.9659 - val_loss: 0.0898 - val_acc: 0.9635\n",
      "Epoch 197/499\n",
      "3599/3599 [==============================] - 0s 74us/step - loss: 0.0825 - acc: 0.9658 - val_loss: 0.0894 - val_acc: 0.9637\n",
      "Epoch 198/499\n",
      "3599/3599 [==============================] - 0s 100us/step - loss: 0.0824 - acc: 0.9660 - val_loss: 0.0896 - val_acc: 0.9636\n",
      "Epoch 199/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0823 - acc: 0.9659 - val_loss: 0.0895 - val_acc: 0.9637\n",
      "Epoch 200/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0822 - acc: 0.9660 - val_loss: 0.0892 - val_acc: 0.9638\n",
      "Epoch 201/499\n",
      "3599/3599 [==============================] - 0s 82us/step - loss: 0.0821 - acc: 0.9660 - val_loss: 0.0892 - val_acc: 0.9637\n",
      "Epoch 202/499\n",
      "3599/3599 [==============================] - 0s 80us/step - loss: 0.0821 - acc: 0.9660 - val_loss: 0.0892 - val_acc: 0.9637\n",
      "Epoch 203/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0820 - acc: 0.9661 - val_loss: 0.0891 - val_acc: 0.9637\n",
      "Epoch 204/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0819 - acc: 0.9660 - val_loss: 0.0891 - val_acc: 0.9636\n",
      "Epoch 205/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.0818 - acc: 0.9662 - val_loss: 0.0893 - val_acc: 0.9636\n",
      "Epoch 206/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0817 - acc: 0.9662 - val_loss: 0.0889 - val_acc: 0.9638\n",
      "Epoch 207/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0816 - acc: 0.9663 - val_loss: 0.0888 - val_acc: 0.9638\n",
      "Epoch 208/499\n",
      "3599/3599 [==============================] - 0s 80us/step - loss: 0.0815 - acc: 0.9663 - val_loss: 0.0889 - val_acc: 0.9640\n",
      "Epoch 209/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0814 - acc: 0.9663 - val_loss: 0.0887 - val_acc: 0.9639\n",
      "Epoch 210/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0814 - acc: 0.9664 - val_loss: 0.0886 - val_acc: 0.9637\n",
      "Epoch 211/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0814 - acc: 0.9664 - val_loss: 0.0884 - val_acc: 0.9640\n",
      "Epoch 212/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0813 - acc: 0.9664 - val_loss: 0.0889 - val_acc: 0.9639\n",
      "Epoch 213/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0812 - acc: 0.9664 - val_loss: 0.0882 - val_acc: 0.9641\n",
      "Epoch 214/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0811 - acc: 0.9664 - val_loss: 0.0882 - val_acc: 0.9639\n",
      "Epoch 215/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0811 - acc: 0.9666 - val_loss: 0.0883 - val_acc: 0.9635\n",
      "Epoch 216/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0810 - acc: 0.9665 - val_loss: 0.0880 - val_acc: 0.9641\n",
      "Epoch 217/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0809 - acc: 0.9666 - val_loss: 0.0881 - val_acc: 0.9638\n",
      "Epoch 218/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0808 - acc: 0.9666 - val_loss: 0.0880 - val_acc: 0.9638\n",
      "Epoch 219/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0808 - acc: 0.9665 - val_loss: 0.0882 - val_acc: 0.9639\n",
      "Epoch 220/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0807 - acc: 0.9667 - val_loss: 0.0881 - val_acc: 0.9639\n",
      "Epoch 221/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0806 - acc: 0.9667 - val_loss: 0.0878 - val_acc: 0.9642\n",
      "Epoch 222/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0805 - acc: 0.9667 - val_loss: 0.0877 - val_acc: 0.9642\n",
      "Epoch 223/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0804 - acc: 0.9667 - val_loss: 0.0876 - val_acc: 0.9643\n",
      "Epoch 224/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0803 - acc: 0.9667 - val_loss: 0.0877 - val_acc: 0.9639\n",
      "Epoch 225/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0803 - acc: 0.9668 - val_loss: 0.0876 - val_acc: 0.9643\n",
      "Epoch 226/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0803 - acc: 0.9668 - val_loss: 0.0873 - val_acc: 0.9646\n",
      "Epoch 227/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0802 - acc: 0.9668 - val_loss: 0.0872 - val_acc: 0.9642\n",
      "Epoch 228/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0800 - acc: 0.9669 - val_loss: 0.0875 - val_acc: 0.9639\n",
      "Epoch 229/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0800 - acc: 0.9670 - val_loss: 0.0875 - val_acc: 0.9643\n",
      "Epoch 230/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0799 - acc: 0.9669 - val_loss: 0.0872 - val_acc: 0.9642\n",
      "Epoch 231/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0798 - acc: 0.9669 - val_loss: 0.0872 - val_acc: 0.9644\n",
      "Epoch 232/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0798 - acc: 0.9671 - val_loss: 0.0871 - val_acc: 0.9643\n",
      "Epoch 233/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0797 - acc: 0.9672 - val_loss: 0.0869 - val_acc: 0.9639\n",
      "Epoch 234/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0796 - acc: 0.9671 - val_loss: 0.0867 - val_acc: 0.9643\n",
      "Epoch 235/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0796 - acc: 0.9672 - val_loss: 0.0868 - val_acc: 0.9644\n",
      "Epoch 236/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.0795 - acc: 0.9671 - val_loss: 0.0869 - val_acc: 0.9640\n",
      "Epoch 237/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0794 - acc: 0.9672 - val_loss: 0.0866 - val_acc: 0.9644\n",
      "Epoch 238/499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0794 - acc: 0.9672 - val_loss: 0.0865 - val_acc: 0.9645\n",
      "Epoch 239/499\n",
      "3599/3599 [==============================] - 0s 58us/step - loss: 0.0793 - acc: 0.9673 - val_loss: 0.0864 - val_acc: 0.9643\n",
      "Epoch 240/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0792 - acc: 0.9672 - val_loss: 0.0864 - val_acc: 0.9646\n",
      "Epoch 241/499\n",
      "3599/3599 [==============================] - 0s 58us/step - loss: 0.0791 - acc: 0.9672 - val_loss: 0.0866 - val_acc: 0.9649\n",
      "Epoch 242/499\n",
      "3599/3599 [==============================] - 0s 58us/step - loss: 0.0791 - acc: 0.9674 - val_loss: 0.0868 - val_acc: 0.9642\n",
      "Epoch 243/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0790 - acc: 0.9675 - val_loss: 0.0864 - val_acc: 0.9649\n",
      "Epoch 244/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0789 - acc: 0.9674 - val_loss: 0.0863 - val_acc: 0.9640\n",
      "Epoch 245/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0789 - acc: 0.9674 - val_loss: 0.0862 - val_acc: 0.9646\n",
      "Epoch 246/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0789 - acc: 0.9675 - val_loss: 0.0865 - val_acc: 0.9644\n",
      "Epoch 247/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0789 - acc: 0.9673 - val_loss: 0.0863 - val_acc: 0.9647\n",
      "Epoch 248/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0788 - acc: 0.9674 - val_loss: 0.0861 - val_acc: 0.9646\n",
      "Epoch 249/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0787 - acc: 0.9674 - val_loss: 0.0857 - val_acc: 0.9647\n",
      "Epoch 250/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0786 - acc: 0.9676 - val_loss: 0.0858 - val_acc: 0.9649\n",
      "Epoch 251/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0785 - acc: 0.9676 - val_loss: 0.0859 - val_acc: 0.9647\n",
      "Epoch 252/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0785 - acc: 0.9675 - val_loss: 0.0855 - val_acc: 0.9648\n",
      "Epoch 253/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0784 - acc: 0.9676 - val_loss: 0.0855 - val_acc: 0.9647\n",
      "Epoch 254/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0784 - acc: 0.9677 - val_loss: 0.0855 - val_acc: 0.9652\n",
      "Epoch 255/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0783 - acc: 0.9677 - val_loss: 0.0854 - val_acc: 0.9651\n",
      "Epoch 256/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0783 - acc: 0.9676 - val_loss: 0.0854 - val_acc: 0.9654\n",
      "Epoch 257/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0782 - acc: 0.9677 - val_loss: 0.0856 - val_acc: 0.9647\n",
      "Epoch 258/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0781 - acc: 0.9677 - val_loss: 0.0855 - val_acc: 0.9649\n",
      "Epoch 259/499\n",
      "3599/3599 [==============================] - 0s 58us/step - loss: 0.0781 - acc: 0.9678 - val_loss: 0.0853 - val_acc: 0.9651\n",
      "Epoch 260/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0780 - acc: 0.9678 - val_loss: 0.0853 - val_acc: 0.9652\n",
      "Epoch 261/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0780 - acc: 0.9678 - val_loss: 0.0851 - val_acc: 0.9650\n",
      "Epoch 262/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0779 - acc: 0.9678 - val_loss: 0.0849 - val_acc: 0.9654\n",
      "Epoch 263/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0778 - acc: 0.9679 - val_loss: 0.0852 - val_acc: 0.9654\n",
      "Epoch 264/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0778 - acc: 0.9677 - val_loss: 0.0850 - val_acc: 0.9654\n",
      "Epoch 265/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0778 - acc: 0.9679 - val_loss: 0.0849 - val_acc: 0.9654\n",
      "Epoch 266/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0777 - acc: 0.9679 - val_loss: 0.0849 - val_acc: 0.9651\n",
      "Epoch 267/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0777 - acc: 0.9679 - val_loss: 0.0848 - val_acc: 0.9652\n",
      "Epoch 268/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0776 - acc: 0.9680 - val_loss: 0.0850 - val_acc: 0.9650\n",
      "Epoch 269/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0775 - acc: 0.9680 - val_loss: 0.0847 - val_acc: 0.9657\n",
      "Epoch 270/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0775 - acc: 0.9679 - val_loss: 0.0846 - val_acc: 0.9653\n",
      "Epoch 271/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0774 - acc: 0.9680 - val_loss: 0.0848 - val_acc: 0.9649\n",
      "Epoch 272/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0774 - acc: 0.9680 - val_loss: 0.0848 - val_acc: 0.9654\n",
      "Epoch 273/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0774 - acc: 0.9680 - val_loss: 0.0846 - val_acc: 0.9651\n",
      "Epoch 274/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0773 - acc: 0.9680 - val_loss: 0.0846 - val_acc: 0.9655\n",
      "Epoch 275/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0772 - acc: 0.9681 - val_loss: 0.0845 - val_acc: 0.9658\n",
      "Epoch 276/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0771 - acc: 0.9682 - val_loss: 0.0845 - val_acc: 0.9655\n",
      "Epoch 277/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0771 - acc: 0.9681 - val_loss: 0.0844 - val_acc: 0.9654\n",
      "Epoch 278/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0772 - acc: 0.9681 - val_loss: 0.0843 - val_acc: 0.9655\n",
      "Epoch 279/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0770 - acc: 0.9681 - val_loss: 0.0845 - val_acc: 0.9652\n",
      "Epoch 280/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0771 - acc: 0.9680 - val_loss: 0.0841 - val_acc: 0.9655\n",
      "Epoch 281/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0768 - acc: 0.9682 - val_loss: 0.0843 - val_acc: 0.9654\n",
      "Epoch 282/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0769 - acc: 0.9682 - val_loss: 0.0844 - val_acc: 0.9655\n",
      "Epoch 283/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0768 - acc: 0.9681 - val_loss: 0.0842 - val_acc: 0.9657\n",
      "Epoch 284/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0768 - acc: 0.9682 - val_loss: 0.0843 - val_acc: 0.9654\n",
      "Epoch 285/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0767 - acc: 0.9683 - val_loss: 0.0841 - val_acc: 0.9655\n",
      "Epoch 286/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0766 - acc: 0.9682 - val_loss: 0.0841 - val_acc: 0.9663\n",
      "Epoch 287/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0766 - acc: 0.9682 - val_loss: 0.0840 - val_acc: 0.9657\n",
      "Epoch 288/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0766 - acc: 0.9683 - val_loss: 0.0842 - val_acc: 0.9654\n",
      "Epoch 289/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0766 - acc: 0.9683 - val_loss: 0.0840 - val_acc: 0.9656\n",
      "Epoch 290/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0764 - acc: 0.9683 - val_loss: 0.0842 - val_acc: 0.9654\n",
      "Epoch 291/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0764 - acc: 0.9683 - val_loss: 0.0839 - val_acc: 0.9655\n",
      "Epoch 292/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0763 - acc: 0.9683 - val_loss: 0.0840 - val_acc: 0.9655\n",
      "Epoch 293/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0763 - acc: 0.9683 - val_loss: 0.0837 - val_acc: 0.9657\n",
      "Epoch 294/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0762 - acc: 0.9683 - val_loss: 0.0840 - val_acc: 0.9657\n",
      "Epoch 295/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0763 - acc: 0.9684 - val_loss: 0.0836 - val_acc: 0.9659\n",
      "Epoch 296/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0762 - acc: 0.9685 - val_loss: 0.0836 - val_acc: 0.9655\n",
      "Epoch 297/499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0761 - acc: 0.9685 - val_loss: 0.0836 - val_acc: 0.9661\n",
      "Epoch 298/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0760 - acc: 0.9685 - val_loss: 0.0834 - val_acc: 0.9658\n",
      "Epoch 299/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0761 - acc: 0.9685 - val_loss: 0.0833 - val_acc: 0.9657\n",
      "Epoch 300/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0760 - acc: 0.9685 - val_loss: 0.0836 - val_acc: 0.9654\n",
      "Epoch 301/499\n",
      "3599/3599 [==============================] - 0s 75us/step - loss: 0.0759 - acc: 0.9685 - val_loss: 0.0836 - val_acc: 0.9656\n",
      "Epoch 302/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0759 - acc: 0.9685 - val_loss: 0.0834 - val_acc: 0.9659\n",
      "Epoch 303/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0758 - acc: 0.9686 - val_loss: 0.0832 - val_acc: 0.9661\n",
      "Epoch 304/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0758 - acc: 0.9685 - val_loss: 0.0833 - val_acc: 0.9649\n",
      "Epoch 305/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0758 - acc: 0.9686 - val_loss: 0.0831 - val_acc: 0.9662\n",
      "Epoch 306/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0758 - acc: 0.9686 - val_loss: 0.0831 - val_acc: 0.9657\n",
      "Epoch 307/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0757 - acc: 0.9687 - val_loss: 0.0832 - val_acc: 0.9660\n",
      "Epoch 308/499\n",
      "3599/3599 [==============================] - 0s 75us/step - loss: 0.0756 - acc: 0.9687 - val_loss: 0.0833 - val_acc: 0.9660\n",
      "Epoch 309/499\n",
      "3599/3599 [==============================] - 0s 94us/step - loss: 0.0756 - acc: 0.9686 - val_loss: 0.0831 - val_acc: 0.9665\n",
      "Epoch 310/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0756 - acc: 0.9686 - val_loss: 0.0830 - val_acc: 0.9662\n",
      "Epoch 311/499\n",
      "3599/3599 [==============================] - 0s 92us/step - loss: 0.0756 - acc: 0.9686 - val_loss: 0.0834 - val_acc: 0.9661\n",
      "Epoch 312/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0755 - acc: 0.9685 - val_loss: 0.0829 - val_acc: 0.9657\n",
      "Epoch 313/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0754 - acc: 0.9686 - val_loss: 0.0830 - val_acc: 0.9658\n",
      "Epoch 314/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0754 - acc: 0.9687 - val_loss: 0.0826 - val_acc: 0.9664\n",
      "Epoch 315/499\n",
      "3599/3599 [==============================] - 0s 80us/step - loss: 0.0753 - acc: 0.9687 - val_loss: 0.0828 - val_acc: 0.9660\n",
      "Epoch 316/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0754 - acc: 0.9687 - val_loss: 0.0828 - val_acc: 0.9658\n",
      "Epoch 317/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0753 - acc: 0.9688 - val_loss: 0.0830 - val_acc: 0.9660\n",
      "Epoch 318/499\n",
      "3599/3599 [==============================] - 0s 86us/step - loss: 0.0753 - acc: 0.9687 - val_loss: 0.0829 - val_acc: 0.9663\n",
      "Epoch 319/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0752 - acc: 0.9689 - val_loss: 0.0829 - val_acc: 0.9660\n",
      "Epoch 320/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0752 - acc: 0.9687 - val_loss: 0.0828 - val_acc: 0.9660\n",
      "Epoch 321/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0752 - acc: 0.9688 - val_loss: 0.0829 - val_acc: 0.9657\n",
      "Epoch 322/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0751 - acc: 0.9688 - val_loss: 0.0825 - val_acc: 0.9662\n",
      "Epoch 323/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0751 - acc: 0.9688 - val_loss: 0.0827 - val_acc: 0.9659\n",
      "Epoch 324/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0750 - acc: 0.9688 - val_loss: 0.0825 - val_acc: 0.9663\n",
      "Epoch 325/499\n",
      "3599/3599 [==============================] - 0s 75us/step - loss: 0.0750 - acc: 0.9689 - val_loss: 0.0824 - val_acc: 0.9662\n",
      "Epoch 326/499\n",
      "3599/3599 [==============================] - 0s 77us/step - loss: 0.0749 - acc: 0.9688 - val_loss: 0.0830 - val_acc: 0.9654\n",
      "Epoch 327/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0749 - acc: 0.9689 - val_loss: 0.0824 - val_acc: 0.9662\n",
      "Epoch 328/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0749 - acc: 0.9689 - val_loss: 0.0824 - val_acc: 0.9663\n",
      "Epoch 329/499\n",
      "3599/3599 [==============================] - 0s 80us/step - loss: 0.0749 - acc: 0.9688 - val_loss: 0.0823 - val_acc: 0.9664\n",
      "Epoch 330/499\n",
      "3599/3599 [==============================] - 0s 79us/step - loss: 0.0748 - acc: 0.9688 - val_loss: 0.0821 - val_acc: 0.9663\n",
      "Epoch 331/499\n",
      "3599/3599 [==============================] - 0s 74us/step - loss: 0.0748 - acc: 0.9688 - val_loss: 0.0822 - val_acc: 0.9656\n",
      "Epoch 332/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0747 - acc: 0.9689 - val_loss: 0.0824 - val_acc: 0.9662\n",
      "Epoch 333/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0748 - acc: 0.9688 - val_loss: 0.0822 - val_acc: 0.9663\n",
      "Epoch 334/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0747 - acc: 0.9688 - val_loss: 0.0823 - val_acc: 0.9659\n",
      "Epoch 335/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0746 - acc: 0.9689 - val_loss: 0.0820 - val_acc: 0.9663\n",
      "Epoch 336/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0746 - acc: 0.9689 - val_loss: 0.0826 - val_acc: 0.9659\n",
      "Epoch 337/499\n",
      "3599/3599 [==============================] - 0s 77us/step - loss: 0.0746 - acc: 0.9689 - val_loss: 0.0823 - val_acc: 0.9661\n",
      "Epoch 338/499\n",
      "3599/3599 [==============================] - 0s 70us/step - loss: 0.0745 - acc: 0.9689 - val_loss: 0.0823 - val_acc: 0.9662\n",
      "Epoch 339/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0745 - acc: 0.9689 - val_loss: 0.0820 - val_acc: 0.9662\n",
      "Epoch 340/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0744 - acc: 0.9691 - val_loss: 0.0821 - val_acc: 0.9659\n",
      "Epoch 341/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0744 - acc: 0.9689 - val_loss: 0.0819 - val_acc: 0.9663\n",
      "Epoch 342/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0744 - acc: 0.9690 - val_loss: 0.0820 - val_acc: 0.9661\n",
      "Epoch 343/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0744 - acc: 0.9690 - val_loss: 0.0821 - val_acc: 0.9660\n",
      "Epoch 344/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0743 - acc: 0.9691 - val_loss: 0.0821 - val_acc: 0.9662\n",
      "Epoch 345/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0743 - acc: 0.9690 - val_loss: 0.0824 - val_acc: 0.9661\n",
      "Epoch 346/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0742 - acc: 0.9690 - val_loss: 0.0821 - val_acc: 0.9657\n",
      "Epoch 347/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0742 - acc: 0.9691 - val_loss: 0.0818 - val_acc: 0.9663\n",
      "Epoch 348/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0742 - acc: 0.9690 - val_loss: 0.0818 - val_acc: 0.9665\n",
      "Epoch 349/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0742 - acc: 0.9691 - val_loss: 0.0817 - val_acc: 0.9663\n",
      "Epoch 350/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0741 - acc: 0.9692 - val_loss: 0.0818 - val_acc: 0.9665\n",
      "Epoch 351/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0741 - acc: 0.9692 - val_loss: 0.0816 - val_acc: 0.9663\n",
      "Epoch 352/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0741 - acc: 0.9692 - val_loss: 0.0817 - val_acc: 0.9660\n",
      "Epoch 353/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0740 - acc: 0.9692 - val_loss: 0.0816 - val_acc: 0.9663\n",
      "Epoch 354/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0740 - acc: 0.9691 - val_loss: 0.0815 - val_acc: 0.9661\n",
      "Epoch 355/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0739 - acc: 0.9692 - val_loss: 0.0816 - val_acc: 0.9662\n",
      "Epoch 356/499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 0s 85us/step - loss: 0.0739 - acc: 0.9689 - val_loss: 0.0816 - val_acc: 0.9662\n",
      "Epoch 357/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0739 - acc: 0.9691 - val_loss: 0.0818 - val_acc: 0.9662\n",
      "Epoch 358/499\n",
      "3599/3599 [==============================] - 0s 90us/step - loss: 0.0738 - acc: 0.9692 - val_loss: 0.0814 - val_acc: 0.9662\n",
      "Epoch 359/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0738 - acc: 0.9692 - val_loss: 0.0816 - val_acc: 0.9660\n",
      "Epoch 360/499\n",
      "3599/3599 [==============================] - 0s 85us/step - loss: 0.0738 - acc: 0.9691 - val_loss: 0.0814 - val_acc: 0.9663\n",
      "Epoch 361/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0738 - acc: 0.9692 - val_loss: 0.0815 - val_acc: 0.9663\n",
      "Epoch 362/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.0737 - acc: 0.9693 - val_loss: 0.0814 - val_acc: 0.9666\n",
      "Epoch 363/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.0737 - acc: 0.9691 - val_loss: 0.0813 - val_acc: 0.9666\n",
      "Epoch 364/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0737 - acc: 0.9693 - val_loss: 0.0814 - val_acc: 0.9665\n",
      "Epoch 365/499\n",
      "3599/3599 [==============================] - 0s 71us/step - loss: 0.0736 - acc: 0.9692 - val_loss: 0.0813 - val_acc: 0.9664\n",
      "Epoch 366/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0736 - acc: 0.9693 - val_loss: 0.0812 - val_acc: 0.9662\n",
      "Epoch 367/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0736 - acc: 0.9692 - val_loss: 0.0812 - val_acc: 0.9665\n",
      "Epoch 368/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0735 - acc: 0.9694 - val_loss: 0.0814 - val_acc: 0.9662\n",
      "Epoch 369/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0735 - acc: 0.9693 - val_loss: 0.0811 - val_acc: 0.9663\n",
      "Epoch 370/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0735 - acc: 0.9693 - val_loss: 0.0812 - val_acc: 0.9668\n",
      "Epoch 371/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0735 - acc: 0.9693 - val_loss: 0.0810 - val_acc: 0.9667\n",
      "Epoch 372/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0735 - acc: 0.9693 - val_loss: 0.0811 - val_acc: 0.9662\n",
      "Epoch 373/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0734 - acc: 0.9693 - val_loss: 0.0812 - val_acc: 0.9660\n",
      "Epoch 374/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0734 - acc: 0.9693 - val_loss: 0.0812 - val_acc: 0.9663\n",
      "Epoch 375/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0734 - acc: 0.9694 - val_loss: 0.0815 - val_acc: 0.9663\n",
      "Epoch 376/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0734 - acc: 0.9692 - val_loss: 0.0811 - val_acc: 0.9665\n",
      "Epoch 377/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0733 - acc: 0.9694 - val_loss: 0.0810 - val_acc: 0.9666\n",
      "Epoch 378/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0733 - acc: 0.9694 - val_loss: 0.0811 - val_acc: 0.9657\n",
      "Epoch 379/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0733 - acc: 0.9694 - val_loss: 0.0811 - val_acc: 0.9659\n",
      "Epoch 380/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0732 - acc: 0.9693 - val_loss: 0.0811 - val_acc: 0.9663\n",
      "Epoch 381/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0732 - acc: 0.9694 - val_loss: 0.0809 - val_acc: 0.9665\n",
      "Epoch 382/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0732 - acc: 0.9695 - val_loss: 0.0810 - val_acc: 0.9664\n",
      "Epoch 383/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0731 - acc: 0.9694 - val_loss: 0.0809 - val_acc: 0.9661\n",
      "Epoch 384/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0732 - acc: 0.9694 - val_loss: 0.0810 - val_acc: 0.9668\n",
      "Epoch 385/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0731 - acc: 0.9693 - val_loss: 0.0808 - val_acc: 0.9666\n",
      "Epoch 386/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0731 - acc: 0.9695 - val_loss: 0.0808 - val_acc: 0.9667\n",
      "Epoch 387/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0731 - acc: 0.9695 - val_loss: 0.0805 - val_acc: 0.9664\n",
      "Epoch 388/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0731 - acc: 0.9694 - val_loss: 0.0806 - val_acc: 0.9666\n",
      "Epoch 389/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0729 - acc: 0.9694 - val_loss: 0.0808 - val_acc: 0.9663\n",
      "Epoch 390/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0730 - acc: 0.9694 - val_loss: 0.0806 - val_acc: 0.9662\n",
      "Epoch 391/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0729 - acc: 0.9694 - val_loss: 0.0806 - val_acc: 0.9661\n",
      "Epoch 392/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0729 - acc: 0.9695 - val_loss: 0.0806 - val_acc: 0.9662\n",
      "Epoch 393/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0729 - acc: 0.9695 - val_loss: 0.0807 - val_acc: 0.9664\n",
      "Epoch 394/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0728 - acc: 0.9693 - val_loss: 0.0804 - val_acc: 0.9664\n",
      "Epoch 395/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0728 - acc: 0.9695 - val_loss: 0.0803 - val_acc: 0.9669\n",
      "Epoch 396/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0728 - acc: 0.9695 - val_loss: 0.0806 - val_acc: 0.9664\n",
      "Epoch 397/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0727 - acc: 0.9695 - val_loss: 0.0806 - val_acc: 0.9665\n",
      "Epoch 398/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0727 - acc: 0.9695 - val_loss: 0.0805 - val_acc: 0.9663\n",
      "Epoch 399/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0727 - acc: 0.9696 - val_loss: 0.0806 - val_acc: 0.9666\n",
      "Epoch 400/499\n",
      "3599/3599 [==============================] - 0s 76us/step - loss: 0.0727 - acc: 0.9695 - val_loss: 0.0807 - val_acc: 0.9664\n",
      "Epoch 401/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0726 - acc: 0.9696 - val_loss: 0.0805 - val_acc: 0.9669\n",
      "Epoch 402/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0725 - acc: 0.9696 - val_loss: 0.0804 - val_acc: 0.9667\n",
      "Epoch 403/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0727 - acc: 0.9695 - val_loss: 0.0804 - val_acc: 0.9666\n",
      "Epoch 404/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0726 - acc: 0.9695 - val_loss: 0.0807 - val_acc: 0.9663\n",
      "Epoch 405/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0725 - acc: 0.9695 - val_loss: 0.0803 - val_acc: 0.9669\n",
      "Epoch 406/499\n",
      "3599/3599 [==============================] - 0s 73us/step - loss: 0.0725 - acc: 0.9695 - val_loss: 0.0805 - val_acc: 0.9661\n",
      "Epoch 407/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0725 - acc: 0.9696 - val_loss: 0.0805 - val_acc: 0.9664\n",
      "Epoch 408/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0725 - acc: 0.9696 - val_loss: 0.0803 - val_acc: 0.9666\n",
      "Epoch 409/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0725 - acc: 0.9696 - val_loss: 0.0804 - val_acc: 0.9666\n",
      "Epoch 410/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0724 - acc: 0.9696 - val_loss: 0.0805 - val_acc: 0.9668\n",
      "Epoch 411/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0724 - acc: 0.9697 - val_loss: 0.0803 - val_acc: 0.9665\n",
      "Epoch 412/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0725 - acc: 0.9697 - val_loss: 0.0801 - val_acc: 0.9671\n",
      "Epoch 413/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0724 - acc: 0.9696 - val_loss: 0.0807 - val_acc: 0.9660\n",
      "Epoch 414/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0724 - acc: 0.9697 - val_loss: 0.0802 - val_acc: 0.9668\n",
      "Epoch 415/499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0724 - acc: 0.9697 - val_loss: 0.0801 - val_acc: 0.9667\n",
      "Epoch 416/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0723 - acc: 0.9697 - val_loss: 0.0801 - val_acc: 0.9664\n",
      "Epoch 417/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0723 - acc: 0.9697 - val_loss: 0.0801 - val_acc: 0.9665\n",
      "Epoch 418/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0722 - acc: 0.9697 - val_loss: 0.0803 - val_acc: 0.9665\n",
      "Epoch 419/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0723 - acc: 0.9697 - val_loss: 0.0799 - val_acc: 0.9663\n",
      "Epoch 420/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0722 - acc: 0.9697 - val_loss: 0.0801 - val_acc: 0.9662\n",
      "Epoch 421/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0722 - acc: 0.9697 - val_loss: 0.0802 - val_acc: 0.9664\n",
      "Epoch 422/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0721 - acc: 0.9698 - val_loss: 0.0798 - val_acc: 0.9664\n",
      "Epoch 423/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0721 - acc: 0.9696 - val_loss: 0.0803 - val_acc: 0.9668\n",
      "Epoch 424/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0721 - acc: 0.9698 - val_loss: 0.0799 - val_acc: 0.9665\n",
      "Epoch 425/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0721 - acc: 0.9698 - val_loss: 0.0799 - val_acc: 0.9662\n",
      "Epoch 426/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0721 - acc: 0.9698 - val_loss: 0.0800 - val_acc: 0.9665\n",
      "Epoch 427/499\n",
      "3599/3599 [==============================] - 0s 79us/step - loss: 0.0720 - acc: 0.9698 - val_loss: 0.0799 - val_acc: 0.9668\n",
      "Epoch 428/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0720 - acc: 0.9697 - val_loss: 0.0798 - val_acc: 0.9667\n",
      "Epoch 429/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0720 - acc: 0.9697 - val_loss: 0.0797 - val_acc: 0.9671\n",
      "Epoch 430/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0720 - acc: 0.9698 - val_loss: 0.0803 - val_acc: 0.9665\n",
      "Epoch 431/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0720 - acc: 0.9697 - val_loss: 0.0799 - val_acc: 0.9668\n",
      "Epoch 432/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0719 - acc: 0.9697 - val_loss: 0.0798 - val_acc: 0.9671\n",
      "Epoch 433/499\n",
      "3599/3599 [==============================] - 0s 97us/step - loss: 0.0719 - acc: 0.9697 - val_loss: 0.0796 - val_acc: 0.9670\n",
      "Epoch 434/499\n",
      "3599/3599 [==============================] - 0s 88us/step - loss: 0.0719 - acc: 0.9699 - val_loss: 0.0796 - val_acc: 0.9668\n",
      "Epoch 435/499\n",
      "3599/3599 [==============================] - 0s 69us/step - loss: 0.0719 - acc: 0.9698 - val_loss: 0.0799 - val_acc: 0.9666\n",
      "Epoch 436/499\n",
      "3599/3599 [==============================] - 0s 68us/step - loss: 0.0718 - acc: 0.9697 - val_loss: 0.0798 - val_acc: 0.9666\n",
      "Epoch 437/499\n",
      "3599/3599 [==============================] - 0s 78us/step - loss: 0.0719 - acc: 0.9697 - val_loss: 0.0797 - val_acc: 0.9669\n",
      "Epoch 438/499\n",
      "3599/3599 [==============================] - 0s 72us/step - loss: 0.0718 - acc: 0.9697 - val_loss: 0.0800 - val_acc: 0.9666\n",
      "Epoch 439/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0718 - acc: 0.9697 - val_loss: 0.0796 - val_acc: 0.9667\n",
      "Epoch 440/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0718 - acc: 0.9698 - val_loss: 0.0795 - val_acc: 0.9667\n",
      "Epoch 441/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0717 - acc: 0.9698 - val_loss: 0.0794 - val_acc: 0.9668\n",
      "Epoch 442/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0717 - acc: 0.9699 - val_loss: 0.0797 - val_acc: 0.9664\n",
      "Epoch 443/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0717 - acc: 0.9699 - val_loss: 0.0797 - val_acc: 0.9662\n",
      "Epoch 444/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0716 - acc: 0.9699 - val_loss: 0.0796 - val_acc: 0.9666\n",
      "Epoch 445/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0717 - acc: 0.9700 - val_loss: 0.0796 - val_acc: 0.9668\n",
      "Epoch 446/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0717 - acc: 0.9699 - val_loss: 0.0795 - val_acc: 0.9667\n",
      "Epoch 447/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0717 - acc: 0.9699 - val_loss: 0.0795 - val_acc: 0.9667\n",
      "Epoch 448/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0716 - acc: 0.9699 - val_loss: 0.0795 - val_acc: 0.9671\n",
      "Epoch 449/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0715 - acc: 0.9699 - val_loss: 0.0794 - val_acc: 0.9669\n",
      "Epoch 450/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0715 - acc: 0.9699 - val_loss: 0.0795 - val_acc: 0.9672\n",
      "Epoch 451/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0715 - acc: 0.9699 - val_loss: 0.0797 - val_acc: 0.9665\n",
      "Epoch 452/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0715 - acc: 0.9700 - val_loss: 0.0795 - val_acc: 0.9670\n",
      "Epoch 453/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0715 - acc: 0.9700 - val_loss: 0.0796 - val_acc: 0.9670\n",
      "Epoch 454/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0714 - acc: 0.9700 - val_loss: 0.0794 - val_acc: 0.9669\n",
      "Epoch 455/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0714 - acc: 0.9701 - val_loss: 0.0794 - val_acc: 0.9665\n",
      "Epoch 456/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0715 - acc: 0.9700 - val_loss: 0.0794 - val_acc: 0.9667\n",
      "Epoch 457/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0714 - acc: 0.9699 - val_loss: 0.0794 - val_acc: 0.9668\n",
      "Epoch 458/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0714 - acc: 0.9699 - val_loss: 0.0795 - val_acc: 0.9670\n",
      "Epoch 459/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0714 - acc: 0.9699 - val_loss: 0.0796 - val_acc: 0.9666\n",
      "Epoch 460/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0714 - acc: 0.9700 - val_loss: 0.0793 - val_acc: 0.9667\n",
      "Epoch 461/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0713 - acc: 0.9700 - val_loss: 0.0793 - val_acc: 0.9668\n",
      "Epoch 462/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0713 - acc: 0.9698 - val_loss: 0.0798 - val_acc: 0.9665\n",
      "Epoch 463/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0713 - acc: 0.9700 - val_loss: 0.0794 - val_acc: 0.9665\n",
      "Epoch 464/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0714 - acc: 0.9700 - val_loss: 0.0792 - val_acc: 0.9670\n",
      "Epoch 465/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0714 - acc: 0.9699 - val_loss: 0.0792 - val_acc: 0.9669\n",
      "Epoch 466/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0712 - acc: 0.9700 - val_loss: 0.0793 - val_acc: 0.9666\n",
      "Epoch 467/499\n",
      "3599/3599 [==============================] - 0s 67us/step - loss: 0.0713 - acc: 0.9700 - val_loss: 0.0791 - val_acc: 0.9667\n",
      "Epoch 468/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0712 - acc: 0.9700 - val_loss: 0.0791 - val_acc: 0.9669\n",
      "Epoch 469/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0711 - acc: 0.9700 - val_loss: 0.0794 - val_acc: 0.9666\n",
      "Epoch 470/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0711 - acc: 0.9700 - val_loss: 0.0792 - val_acc: 0.9666\n",
      "Epoch 471/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0712 - acc: 0.9701 - val_loss: 0.0792 - val_acc: 0.9671\n",
      "Epoch 472/499\n",
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0711 - acc: 0.9700 - val_loss: 0.0792 - val_acc: 0.9671\n",
      "Epoch 473/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0711 - acc: 0.9701 - val_loss: 0.0792 - val_acc: 0.9671\n",
      "Epoch 474/499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 0s 66us/step - loss: 0.0710 - acc: 0.9702 - val_loss: 0.0794 - val_acc: 0.9669\n",
      "Epoch 475/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0711 - acc: 0.9702 - val_loss: 0.0788 - val_acc: 0.9673\n",
      "Epoch 476/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0710 - acc: 0.9701 - val_loss: 0.0790 - val_acc: 0.9676\n",
      "Epoch 477/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0710 - acc: 0.9703 - val_loss: 0.0790 - val_acc: 0.9673\n",
      "Epoch 478/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0710 - acc: 0.9701 - val_loss: 0.0789 - val_acc: 0.9669\n",
      "Epoch 479/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0710 - acc: 0.9702 - val_loss: 0.0790 - val_acc: 0.9671\n",
      "Epoch 480/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0710 - acc: 0.9702 - val_loss: 0.0791 - val_acc: 0.9670\n",
      "Epoch 481/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0709 - acc: 0.9701 - val_loss: 0.0790 - val_acc: 0.9671\n",
      "Epoch 482/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0709 - acc: 0.9701 - val_loss: 0.0790 - val_acc: 0.9670\n",
      "Epoch 483/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0709 - acc: 0.9703 - val_loss: 0.0788 - val_acc: 0.9667\n",
      "Epoch 484/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0709 - acc: 0.9702 - val_loss: 0.0789 - val_acc: 0.9668\n",
      "Epoch 485/499\n",
      "3599/3599 [==============================] - 0s 60us/step - loss: 0.0708 - acc: 0.9702 - val_loss: 0.0793 - val_acc: 0.9666\n",
      "Epoch 486/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0708 - acc: 0.9701 - val_loss: 0.0789 - val_acc: 0.9672\n",
      "Epoch 487/499\n",
      "3599/3599 [==============================] - 0s 59us/step - loss: 0.0708 - acc: 0.9701 - val_loss: 0.0789 - val_acc: 0.9674\n",
      "Epoch 488/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0708 - acc: 0.9703 - val_loss: 0.0790 - val_acc: 0.9668\n",
      "Epoch 489/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0708 - acc: 0.9701 - val_loss: 0.0788 - val_acc: 0.9670\n",
      "Epoch 490/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0707 - acc: 0.9703 - val_loss: 0.0788 - val_acc: 0.9671\n",
      "Epoch 491/499\n",
      "3599/3599 [==============================] - 0s 62us/step - loss: 0.0708 - acc: 0.9701 - val_loss: 0.0787 - val_acc: 0.9669\n",
      "Epoch 492/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0708 - acc: 0.9702 - val_loss: 0.0788 - val_acc: 0.9669\n",
      "Epoch 493/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0707 - acc: 0.9701 - val_loss: 0.0787 - val_acc: 0.9671\n",
      "Epoch 494/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0707 - acc: 0.9703 - val_loss: 0.0791 - val_acc: 0.9670\n",
      "Epoch 495/499\n",
      "3599/3599 [==============================] - 0s 65us/step - loss: 0.0707 - acc: 0.9702 - val_loss: 0.0791 - val_acc: 0.9672\n",
      "Epoch 496/499\n",
      "3599/3599 [==============================] - 0s 61us/step - loss: 0.0706 - acc: 0.9702 - val_loss: 0.0793 - val_acc: 0.9669\n",
      "Epoch 497/499\n",
      "3599/3599 [==============================] - 0s 64us/step - loss: 0.0706 - acc: 0.9702 - val_loss: 0.0788 - val_acc: 0.9669\n",
      "Epoch 498/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0706 - acc: 0.9702 - val_loss: 0.0786 - val_acc: 0.9671\n",
      "Epoch 499/499\n",
      "3599/3599 [==============================] - 0s 63us/step - loss: 0.0705 - acc: 0.9702 - val_loss: 0.0791 - val_acc: 0.9670\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(df_train[\"in\"].values.tolist()), np.array(df_train[\"out\"].values.tolist()), epochs=499, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 24us/step\n",
      "Custo: 0.08021389722824096\n",
      "Acurácia: 0.96665625\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 acertos 3.3 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>numero</th>\n",
       "      <th>pred</th>\n",
       "      <th>romano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3208</td>\n",
       "      <td>MMMCCXX</td>\n",
       "      <td>MMMCCVIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>4994</td>\n",
       "      <td>MMMMDMXCVX</td>\n",
       "      <td>MMMMCMXCIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3997</td>\n",
       "      <td>MMMCMLC</td>\n",
       "      <td>MMMCMXCVII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>2573</td>\n",
       "      <td>MMDLXXI</td>\n",
       "      <td>MMDLXXIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>4184</td>\n",
       "      <td>MMMMCLXXXII</td>\n",
       "      <td>MMMMCLXXXIV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match  numero         pred       romano\n",
       "0  False    3208      MMMCCXX    MMMCCVIII\n",
       "1  False    4994   MMMMDMXCVX   MMMMCMXCIV\n",
       "2  False    3997      MMMCMLC   MMMCMXCVII\n",
       "3  False    2573      MMDLXXI    MMDLXXIII\n",
       "4  False    4184  MMMMCLXXXII  MMMMCLXXXIV"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p500 = evaluate_algorisms(model, df_test)\n",
    "df_p500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_model(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "plot_model(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando por mais épocas, conseguimos um modelo que entende o conceito dos algarismos, mas consegue prever corretamente menos 5% deles. Esse parece ser o limite dessa arquitetura.\n",
    "\n",
    "## Segunda Tentativa\n",
    "Como um modelo pequeno não foi capaz de generalizar o problema, vamos criar um modelo mais profundo (10 camadas ocultas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               1792      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "=================================================================\n",
      "Total params: 166,912\n",
      "Trainable params: 166,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(units=128, activation='relu', input_dim=13))\n",
    "model2.add(Dense(units=128, activation='relu'))\n",
    "model2.add(Dense(units=128, activation='relu'))\n",
    "model2.add(Dense(units=128, activation='relu'))\n",
    "model2.add(Dense(units=128, activation='relu'))\n",
    "model2.add(Dense(units=128, activation='relu'))\n",
    "model2.add(Dense(units=128, activation='relu'))\n",
    "model2.add(Dense(units=128, activation='relu'))\n",
    "model2.add(Dense(units=128, activation='relu'))\n",
    "model2.add(Dense(units=128, activation='relu'))\n",
    "model2.add(Dense(units=128, activation='sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 144us/step\n",
      "Custo: 0.6930582513809204\n",
      "Acurácia: 0.5088203125\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model2, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acertos 0.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>numero</th>\n",
       "      <th>pred</th>\n",
       "      <th>romano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3208</td>\n",
       "      <td>CLCLIVDIXIII LXX</td>\n",
       "      <td>MMMCCVIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>4994</td>\n",
       "      <td>CLCLILDIXIIM LXX</td>\n",
       "      <td>MMMMCMXCIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3997</td>\n",
       "      <td>CLCLILDIXLII LIX</td>\n",
       "      <td>MMMCMXCVII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>2573</td>\n",
       "      <td>CLCLIVDIXIIM CXX</td>\n",
       "      <td>MMDLXXIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>4184</td>\n",
       "      <td>CLCLIVDIXIXI VXX</td>\n",
       "      <td>MMMMCLXXXIV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match  numero              pred       romano\n",
       "0  False    3208  CLCLIVDIXIII LXX    MMMCCVIII\n",
       "1  False    4994  CLCLILDIXIIM LXX   MMMMCMXCIV\n",
       "2  False    3997  CLCLILDIXLII LIX   MMMCMXCVII\n",
       "3  False    2573  CLCLIVDIXIIM CXX    MMDLXXIII\n",
       "4  False    4184  CLCLIVDIXIXI VXX  MMMMCLXXXIV"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_p0 = evaluate_algorisms(model2, df_test)\n",
    "df2_p0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3599 samples, validate on 400 samples\n",
      "Epoch 1/500\n",
      "3599/3599 [==============================] - 1s 243us/step - loss: 0.2463 - acc: 0.9097 - val_loss: 0.1890 - val_acc: 0.9280\n",
      "Epoch 2/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.1845 - acc: 0.9296 - val_loss: 0.1873 - val_acc: 0.9280\n",
      "Epoch 3/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.1831 - acc: 0.9297 - val_loss: 0.1802 - val_acc: 0.9322\n",
      "Epoch 4/500\n",
      "3599/3599 [==============================] - 1s 139us/step - loss: 0.1490 - acc: 0.9392 - val_loss: 0.1443 - val_acc: 0.9398\n",
      "Epoch 5/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.1358 - acc: 0.9416 - val_loss: 0.1349 - val_acc: 0.9413\n",
      "Epoch 6/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.1316 - acc: 0.9431 - val_loss: 0.1308 - val_acc: 0.9437\n",
      "Epoch 7/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.1274 - acc: 0.9451 - val_loss: 0.1282 - val_acc: 0.9451\n",
      "Epoch 8/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.1215 - acc: 0.9476 - val_loss: 0.1226 - val_acc: 0.9473\n",
      "Epoch 9/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.1166 - acc: 0.9497 - val_loss: 0.1178 - val_acc: 0.9497\n",
      "Epoch 10/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.1125 - acc: 0.9518 - val_loss: 0.1136 - val_acc: 0.9513\n",
      "Epoch 11/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.1084 - acc: 0.9533 - val_loss: 0.1081 - val_acc: 0.9536\n",
      "Epoch 12/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.1036 - acc: 0.9553 - val_loss: 0.1076 - val_acc: 0.9523\n",
      "Epoch 13/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.1004 - acc: 0.9564 - val_loss: 0.1014 - val_acc: 0.9563\n",
      "Epoch 14/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0979 - acc: 0.9574 - val_loss: 0.0994 - val_acc: 0.9565\n",
      "Epoch 15/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0956 - acc: 0.9580 - val_loss: 0.1040 - val_acc: 0.9549\n",
      "Epoch 16/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0943 - acc: 0.9586 - val_loss: 0.0976 - val_acc: 0.9579\n",
      "Epoch 17/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0915 - acc: 0.9598 - val_loss: 0.0983 - val_acc: 0.9571\n",
      "Epoch 18/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0913 - acc: 0.9596 - val_loss: 0.0940 - val_acc: 0.9581\n",
      "Epoch 19/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0893 - acc: 0.9604 - val_loss: 0.0930 - val_acc: 0.9599\n",
      "Epoch 20/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0883 - acc: 0.9609 - val_loss: 0.0917 - val_acc: 0.9601\n",
      "Epoch 21/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0871 - acc: 0.9613 - val_loss: 0.0931 - val_acc: 0.9591\n",
      "Epoch 22/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0872 - acc: 0.9614 - val_loss: 0.0909 - val_acc: 0.9600\n",
      "Epoch 23/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0850 - acc: 0.9623 - val_loss: 0.0897 - val_acc: 0.9612\n",
      "Epoch 24/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0839 - acc: 0.9629 - val_loss: 0.0904 - val_acc: 0.9596\n",
      "Epoch 25/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0839 - acc: 0.9626 - val_loss: 0.0875 - val_acc: 0.9617\n",
      "Epoch 26/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0830 - acc: 0.9632 - val_loss: 0.0875 - val_acc: 0.9614\n",
      "Epoch 27/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0824 - acc: 0.9634 - val_loss: 0.0876 - val_acc: 0.9619\n",
      "Epoch 28/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0814 - acc: 0.9638 - val_loss: 0.0881 - val_acc: 0.9606\n",
      "Epoch 29/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0803 - acc: 0.9643 - val_loss: 0.0858 - val_acc: 0.9625\n",
      "Epoch 30/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0790 - acc: 0.9647 - val_loss: 0.0833 - val_acc: 0.9634\n",
      "Epoch 31/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0776 - acc: 0.9656 - val_loss: 0.0850 - val_acc: 0.9629\n",
      "Epoch 32/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0775 - acc: 0.9657 - val_loss: 0.0836 - val_acc: 0.9636\n",
      "Epoch 33/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0755 - acc: 0.9666 - val_loss: 0.0823 - val_acc: 0.9641\n",
      "Epoch 34/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0743 - acc: 0.9671 - val_loss: 0.0814 - val_acc: 0.9641\n",
      "Epoch 35/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0741 - acc: 0.9671 - val_loss: 0.0818 - val_acc: 0.9636\n",
      "Epoch 36/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0730 - acc: 0.9675 - val_loss: 0.0816 - val_acc: 0.9645\n",
      "Epoch 37/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0721 - acc: 0.9681 - val_loss: 0.0787 - val_acc: 0.9657\n",
      "Epoch 38/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0717 - acc: 0.9680 - val_loss: 0.0781 - val_acc: 0.9655\n",
      "Epoch 39/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0705 - acc: 0.9687 - val_loss: 0.0786 - val_acc: 0.9654\n",
      "Epoch 40/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0691 - acc: 0.9691 - val_loss: 0.0793 - val_acc: 0.9657\n",
      "Epoch 41/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0680 - acc: 0.9695 - val_loss: 0.0822 - val_acc: 0.9650\n",
      "Epoch 42/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0683 - acc: 0.9694 - val_loss: 0.0771 - val_acc: 0.9654\n",
      "Epoch 43/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0677 - acc: 0.9696 - val_loss: 0.0757 - val_acc: 0.9671\n",
      "Epoch 44/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0663 - acc: 0.9703 - val_loss: 0.0771 - val_acc: 0.9664\n",
      "Epoch 45/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0661 - acc: 0.9703 - val_loss: 0.0763 - val_acc: 0.9669\n",
      "Epoch 46/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0642 - acc: 0.9714 - val_loss: 0.0782 - val_acc: 0.9659\n",
      "Epoch 47/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0642 - acc: 0.9711 - val_loss: 0.0750 - val_acc: 0.9672\n",
      "Epoch 48/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0646 - acc: 0.9709 - val_loss: 0.0751 - val_acc: 0.9673\n",
      "Epoch 49/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0627 - acc: 0.9717 - val_loss: 0.0729 - val_acc: 0.9684\n",
      "Epoch 50/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0628 - acc: 0.9718 - val_loss: 0.0751 - val_acc: 0.9672\n",
      "Epoch 51/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0617 - acc: 0.9722 - val_loss: 0.0736 - val_acc: 0.9682\n",
      "Epoch 52/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0609 - acc: 0.9722 - val_loss: 0.0740 - val_acc: 0.9683\n",
      "Epoch 53/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0616 - acc: 0.9722 - val_loss: 0.0728 - val_acc: 0.9683\n",
      "Epoch 54/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0598 - acc: 0.9731 - val_loss: 0.0734 - val_acc: 0.9675\n",
      "Epoch 55/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0605 - acc: 0.9726 - val_loss: 0.0722 - val_acc: 0.9683\n",
      "Epoch 56/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0597 - acc: 0.9732 - val_loss: 0.0736 - val_acc: 0.9678\n",
      "Epoch 57/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0580 - acc: 0.9737 - val_loss: 0.0717 - val_acc: 0.9692\n",
      "Epoch 58/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0574 - acc: 0.9739 - val_loss: 0.0714 - val_acc: 0.9696\n",
      "Epoch 59/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0571 - acc: 0.9740 - val_loss: 0.0710 - val_acc: 0.9693\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0575 - acc: 0.9740 - val_loss: 0.0722 - val_acc: 0.9688\n",
      "Epoch 61/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0571 - acc: 0.9741 - val_loss: 0.0723 - val_acc: 0.9691\n",
      "Epoch 62/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0583 - acc: 0.9735 - val_loss: 0.0690 - val_acc: 0.9712\n",
      "Epoch 63/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0566 - acc: 0.9743 - val_loss: 0.0713 - val_acc: 0.9695\n",
      "Epoch 64/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0562 - acc: 0.9746 - val_loss: 0.0690 - val_acc: 0.9703\n",
      "Epoch 65/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0544 - acc: 0.9753 - val_loss: 0.0703 - val_acc: 0.9703\n",
      "Epoch 66/500\n",
      "3599/3599 [==============================] - 1s 167us/step - loss: 0.0546 - acc: 0.9751 - val_loss: 0.0741 - val_acc: 0.9672\n",
      "Epoch 67/500\n",
      "3599/3599 [==============================] - 1s 150us/step - loss: 0.0551 - acc: 0.9750 - val_loss: 0.0697 - val_acc: 0.9701\n",
      "Epoch 68/500\n",
      "3599/3599 [==============================] - 1s 150us/step - loss: 0.0550 - acc: 0.9749 - val_loss: 0.0708 - val_acc: 0.9699\n",
      "Epoch 69/500\n",
      "3599/3599 [==============================] - 1s 158us/step - loss: 0.0557 - acc: 0.9747 - val_loss: 0.0666 - val_acc: 0.9714\n",
      "Epoch 70/500\n",
      "3599/3599 [==============================] - 1s 160us/step - loss: 0.0537 - acc: 0.9754 - val_loss: 0.0689 - val_acc: 0.9704\n",
      "Epoch 71/500\n",
      "3599/3599 [==============================] - 1s 154us/step - loss: 0.0542 - acc: 0.9754 - val_loss: 0.0680 - val_acc: 0.9713\n",
      "Epoch 72/500\n",
      "3599/3599 [==============================] - 1s 166us/step - loss: 0.0547 - acc: 0.9752 - val_loss: 0.0708 - val_acc: 0.9695\n",
      "Epoch 73/500\n",
      "3599/3599 [==============================] - 1s 164us/step - loss: 0.0528 - acc: 0.9759 - val_loss: 0.0678 - val_acc: 0.9709\n",
      "Epoch 74/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0544 - acc: 0.9753 - val_loss: 0.0731 - val_acc: 0.9686\n",
      "Epoch 75/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0544 - acc: 0.9753 - val_loss: 0.0665 - val_acc: 0.9709\n",
      "Epoch 76/500\n",
      "3599/3599 [==============================] - 1s 139us/step - loss: 0.0513 - acc: 0.9766 - val_loss: 0.0660 - val_acc: 0.9715\n",
      "Epoch 77/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0512 - acc: 0.9766 - val_loss: 0.0690 - val_acc: 0.9715\n",
      "Epoch 78/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0504 - acc: 0.9768 - val_loss: 0.0662 - val_acc: 0.9725\n",
      "Epoch 79/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0495 - acc: 0.9775 - val_loss: 0.0694 - val_acc: 0.9712\n",
      "Epoch 80/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0503 - acc: 0.9770 - val_loss: 0.0691 - val_acc: 0.9716\n",
      "Epoch 81/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0520 - acc: 0.9763 - val_loss: 0.0661 - val_acc: 0.9728\n",
      "Epoch 82/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0524 - acc: 0.9761 - val_loss: 0.0696 - val_acc: 0.9708\n",
      "Epoch 83/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0502 - acc: 0.9769 - val_loss: 0.0673 - val_acc: 0.9714\n",
      "Epoch 84/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0494 - acc: 0.9772 - val_loss: 0.0646 - val_acc: 0.9729\n",
      "Epoch 85/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0505 - acc: 0.9771 - val_loss: 0.0668 - val_acc: 0.9721\n",
      "Epoch 86/500\n",
      "3599/3599 [==============================] - 1s 139us/step - loss: 0.0497 - acc: 0.9772 - val_loss: 0.0672 - val_acc: 0.9709\n",
      "Epoch 87/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0482 - acc: 0.9778 - val_loss: 0.0647 - val_acc: 0.9732\n",
      "Epoch 88/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0500 - acc: 0.9772 - val_loss: 0.0630 - val_acc: 0.9729\n",
      "Epoch 89/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0480 - acc: 0.9779 - val_loss: 0.0661 - val_acc: 0.9720\n",
      "Epoch 90/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0491 - acc: 0.9774 - val_loss: 0.0655 - val_acc: 0.9718\n",
      "Epoch 91/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0486 - acc: 0.9775 - val_loss: 0.0657 - val_acc: 0.9720\n",
      "Epoch 92/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0503 - acc: 0.9770 - val_loss: 0.0712 - val_acc: 0.9696\n",
      "Epoch 93/500\n",
      "3599/3599 [==============================] - 1s 139us/step - loss: 0.0503 - acc: 0.9768 - val_loss: 0.0657 - val_acc: 0.9732\n",
      "Epoch 94/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0470 - acc: 0.9782 - val_loss: 0.0640 - val_acc: 0.9732\n",
      "Epoch 95/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0465 - acc: 0.9786 - val_loss: 0.0653 - val_acc: 0.9728\n",
      "Epoch 96/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0467 - acc: 0.9782 - val_loss: 0.0665 - val_acc: 0.9733\n",
      "Epoch 97/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0479 - acc: 0.9781 - val_loss: 0.0671 - val_acc: 0.9710\n",
      "Epoch 98/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0493 - acc: 0.9774 - val_loss: 0.0667 - val_acc: 0.9720\n",
      "Epoch 99/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0480 - acc: 0.9780 - val_loss: 0.0685 - val_acc: 0.9714\n",
      "Epoch 100/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0501 - acc: 0.9771 - val_loss: 0.0657 - val_acc: 0.9728\n",
      "Epoch 101/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0461 - acc: 0.9787 - val_loss: 0.0661 - val_acc: 0.9720\n",
      "Epoch 102/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0452 - acc: 0.9788 - val_loss: 0.0663 - val_acc: 0.9727\n",
      "Epoch 103/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0447 - acc: 0.9794 - val_loss: 0.0647 - val_acc: 0.9729\n",
      "Epoch 104/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0475 - acc: 0.9783 - val_loss: 0.0713 - val_acc: 0.9705\n",
      "Epoch 105/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0480 - acc: 0.9781 - val_loss: 0.0682 - val_acc: 0.9707\n",
      "Epoch 106/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0506 - acc: 0.9770 - val_loss: 0.0675 - val_acc: 0.9720\n",
      "Epoch 107/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0476 - acc: 0.9783 - val_loss: 0.0699 - val_acc: 0.9715\n",
      "Epoch 108/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0483 - acc: 0.9780 - val_loss: 0.0641 - val_acc: 0.9726\n",
      "Epoch 109/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0447 - acc: 0.9792 - val_loss: 0.0666 - val_acc: 0.9724\n",
      "Epoch 110/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0446 - acc: 0.9793 - val_loss: 0.0666 - val_acc: 0.9723\n",
      "Epoch 111/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0435 - acc: 0.9798 - val_loss: 0.0686 - val_acc: 0.9718\n",
      "Epoch 112/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0434 - acc: 0.9798 - val_loss: 0.0658 - val_acc: 0.9721\n",
      "Epoch 113/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0444 - acc: 0.9795 - val_loss: 0.0672 - val_acc: 0.9720\n",
      "Epoch 114/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0498 - acc: 0.9773 - val_loss: 0.0690 - val_acc: 0.9717\n",
      "Epoch 115/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0477 - acc: 0.9782 - val_loss: 0.0700 - val_acc: 0.9706\n",
      "Epoch 116/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0464 - acc: 0.9785 - val_loss: 0.0659 - val_acc: 0.9725\n",
      "Epoch 117/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0451 - acc: 0.9791 - val_loss: 0.0662 - val_acc: 0.9730\n",
      "Epoch 118/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0445 - acc: 0.9795 - val_loss: 0.0683 - val_acc: 0.9725\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0430 - acc: 0.9801 - val_loss: 0.0665 - val_acc: 0.9725\n",
      "Epoch 120/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0442 - acc: 0.9797 - val_loss: 0.0698 - val_acc: 0.9717\n",
      "Epoch 121/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0458 - acc: 0.9790 - val_loss: 0.0657 - val_acc: 0.9724\n",
      "Epoch 122/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0423 - acc: 0.9803 - val_loss: 0.0673 - val_acc: 0.9724\n",
      "Epoch 123/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0425 - acc: 0.9804 - val_loss: 0.0695 - val_acc: 0.9710\n",
      "Epoch 124/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0444 - acc: 0.9796 - val_loss: 0.0649 - val_acc: 0.9726\n",
      "Epoch 125/500\n",
      "3599/3599 [==============================] - 0s 139us/step - loss: 0.0428 - acc: 0.9800 - val_loss: 0.0663 - val_acc: 0.9727\n",
      "Epoch 126/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0459 - acc: 0.9791 - val_loss: 0.0716 - val_acc: 0.9710\n",
      "Epoch 127/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0489 - acc: 0.9777 - val_loss: 0.0695 - val_acc: 0.9721\n",
      "Epoch 128/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0435 - acc: 0.9798 - val_loss: 0.0688 - val_acc: 0.9718\n",
      "Epoch 129/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0434 - acc: 0.9801 - val_loss: 0.0718 - val_acc: 0.9716\n",
      "Epoch 130/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0446 - acc: 0.9793 - val_loss: 0.0670 - val_acc: 0.9714\n",
      "Epoch 131/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0434 - acc: 0.9798 - val_loss: 0.0674 - val_acc: 0.9731\n",
      "Epoch 132/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0414 - acc: 0.9808 - val_loss: 0.0657 - val_acc: 0.9732\n",
      "Epoch 133/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0406 - acc: 0.9811 - val_loss: 0.0695 - val_acc: 0.9728\n",
      "Epoch 134/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0431 - acc: 0.9801 - val_loss: 0.0686 - val_acc: 0.9726\n",
      "Epoch 135/500\n",
      "3599/3599 [==============================] - 0s 139us/step - loss: 0.0436 - acc: 0.9801 - val_loss: 0.0673 - val_acc: 0.9718\n",
      "Epoch 136/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0416 - acc: 0.9807 - val_loss: 0.0657 - val_acc: 0.9729\n",
      "Epoch 137/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0413 - acc: 0.9810 - val_loss: 0.0688 - val_acc: 0.9718\n",
      "Epoch 138/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0449 - acc: 0.9797 - val_loss: 0.0740 - val_acc: 0.9697\n",
      "Epoch 139/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0476 - acc: 0.9787 - val_loss: 0.0701 - val_acc: 0.9715\n",
      "Epoch 140/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0429 - acc: 0.9803 - val_loss: 0.0670 - val_acc: 0.9721\n",
      "Epoch 141/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0403 - acc: 0.9812 - val_loss: 0.0685 - val_acc: 0.9724\n",
      "Epoch 142/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0426 - acc: 0.9807 - val_loss: 0.0680 - val_acc: 0.9720\n",
      "Epoch 143/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0410 - acc: 0.9811 - val_loss: 0.0705 - val_acc: 0.9714\n",
      "Epoch 144/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0400 - acc: 0.9816 - val_loss: 0.0678 - val_acc: 0.9724\n",
      "Epoch 145/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0407 - acc: 0.9813 - val_loss: 0.0729 - val_acc: 0.9714\n",
      "Epoch 146/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0418 - acc: 0.9808 - val_loss: 0.0709 - val_acc: 0.9721\n",
      "Epoch 147/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0440 - acc: 0.9799 - val_loss: 0.0688 - val_acc: 0.9715\n",
      "Epoch 148/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0410 - acc: 0.9811 - val_loss: 0.0681 - val_acc: 0.9725\n",
      "Epoch 149/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0408 - acc: 0.9814 - val_loss: 0.0708 - val_acc: 0.9717\n",
      "Epoch 150/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0408 - acc: 0.9813 - val_loss: 0.0701 - val_acc: 0.9718\n",
      "Epoch 151/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0405 - acc: 0.9814 - val_loss: 0.0718 - val_acc: 0.9724\n",
      "Epoch 152/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0401 - acc: 0.9817 - val_loss: 0.0733 - val_acc: 0.9718\n",
      "Epoch 153/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0399 - acc: 0.9817 - val_loss: 0.0734 - val_acc: 0.9717\n",
      "Epoch 154/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0423 - acc: 0.9808 - val_loss: 0.0729 - val_acc: 0.9701\n",
      "Epoch 155/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0412 - acc: 0.9812 - val_loss: 0.0717 - val_acc: 0.9710\n",
      "Epoch 156/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0386 - acc: 0.9822 - val_loss: 0.0718 - val_acc: 0.9722\n",
      "Epoch 157/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0420 - acc: 0.9809 - val_loss: 0.0721 - val_acc: 0.9713\n",
      "Epoch 158/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0387 - acc: 0.9824 - val_loss: 0.0728 - val_acc: 0.9709\n",
      "Epoch 159/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0386 - acc: 0.9824 - val_loss: 0.0748 - val_acc: 0.9712\n",
      "Epoch 160/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0381 - acc: 0.9826 - val_loss: 0.0735 - val_acc: 0.9717\n",
      "Epoch 161/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0374 - acc: 0.9831 - val_loss: 0.0763 - val_acc: 0.9713\n",
      "Epoch 162/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0402 - acc: 0.9815 - val_loss: 0.0747 - val_acc: 0.9716\n",
      "Epoch 163/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0385 - acc: 0.9825 - val_loss: 0.0748 - val_acc: 0.9711\n",
      "Epoch 164/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0388 - acc: 0.9824 - val_loss: 0.0778 - val_acc: 0.9709\n",
      "Epoch 165/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0407 - acc: 0.9818 - val_loss: 0.0782 - val_acc: 0.9700\n",
      "Epoch 166/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0398 - acc: 0.9818 - val_loss: 0.0763 - val_acc: 0.9709\n",
      "Epoch 167/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0373 - acc: 0.9829 - val_loss: 0.0775 - val_acc: 0.9703\n",
      "Epoch 168/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0407 - acc: 0.9818 - val_loss: 0.0743 - val_acc: 0.9713\n",
      "Epoch 169/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0446 - acc: 0.9805 - val_loss: 0.0754 - val_acc: 0.9708\n",
      "Epoch 170/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0372 - acc: 0.9832 - val_loss: 0.0734 - val_acc: 0.9714\n",
      "Epoch 171/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0361 - acc: 0.9834 - val_loss: 0.0766 - val_acc: 0.9712\n",
      "Epoch 172/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0376 - acc: 0.9830 - val_loss: 0.0833 - val_acc: 0.9692\n",
      "Epoch 173/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0383 - acc: 0.9826 - val_loss: 0.0762 - val_acc: 0.9711\n",
      "Epoch 174/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0379 - acc: 0.9832 - val_loss: 0.0771 - val_acc: 0.9706\n",
      "Epoch 175/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0368 - acc: 0.9833 - val_loss: 0.0785 - val_acc: 0.9712\n",
      "Epoch 176/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0368 - acc: 0.9833 - val_loss: 0.0798 - val_acc: 0.9697\n",
      "Epoch 177/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0378 - acc: 0.9828 - val_loss: 0.0761 - val_acc: 0.9708\n",
      "Epoch 178/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0353 - acc: 0.9840 - val_loss: 0.0818 - val_acc: 0.9696\n",
      "Epoch 179/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0401 - acc: 0.9822 - val_loss: 0.0801 - val_acc: 0.9704\n",
      "Epoch 180/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0376 - acc: 0.9832 - val_loss: 0.0782 - val_acc: 0.9721\n",
      "Epoch 181/500\n",
      "3599/3599 [==============================] - 1s 139us/step - loss: 0.0343 - acc: 0.9845 - val_loss: 0.0822 - val_acc: 0.9714\n",
      "Epoch 182/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0347 - acc: 0.9843 - val_loss: 0.0810 - val_acc: 0.9705\n",
      "Epoch 183/500\n",
      "3599/3599 [==============================] - 0s 139us/step - loss: 0.0343 - acc: 0.9845 - val_loss: 0.0825 - val_acc: 0.9704\n",
      "Epoch 184/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0358 - acc: 0.9839 - val_loss: 0.0828 - val_acc: 0.9698\n",
      "Epoch 185/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0358 - acc: 0.9840 - val_loss: 0.0838 - val_acc: 0.9705\n",
      "Epoch 186/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0354 - acc: 0.9843 - val_loss: 0.0794 - val_acc: 0.9705\n",
      "Epoch 187/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0365 - acc: 0.9836 - val_loss: 0.0794 - val_acc: 0.9720\n",
      "Epoch 188/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0360 - acc: 0.9840 - val_loss: 0.0836 - val_acc: 0.9702\n",
      "Epoch 189/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0379 - acc: 0.9831 - val_loss: 0.0829 - val_acc: 0.9705\n",
      "Epoch 190/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0365 - acc: 0.9838 - val_loss: 0.0822 - val_acc: 0.9704\n",
      "Epoch 191/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0345 - acc: 0.9843 - val_loss: 0.0819 - val_acc: 0.9712\n",
      "Epoch 192/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0330 - acc: 0.9853 - val_loss: 0.0870 - val_acc: 0.9704\n",
      "Epoch 193/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0325 - acc: 0.9854 - val_loss: 0.0846 - val_acc: 0.9714\n",
      "Epoch 194/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0352 - acc: 0.9844 - val_loss: 0.0857 - val_acc: 0.9707\n",
      "Epoch 195/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0357 - acc: 0.9840 - val_loss: 0.0867 - val_acc: 0.9691\n",
      "Epoch 196/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0340 - acc: 0.9848 - val_loss: 0.0845 - val_acc: 0.9709\n",
      "Epoch 197/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0345 - acc: 0.9847 - val_loss: 0.0861 - val_acc: 0.9702\n",
      "Epoch 198/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0343 - acc: 0.9845 - val_loss: 0.0868 - val_acc: 0.9703\n",
      "Epoch 199/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0329 - acc: 0.9852 - val_loss: 0.0853 - val_acc: 0.9710\n",
      "Epoch 200/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0306 - acc: 0.9864 - val_loss: 0.0898 - val_acc: 0.9713\n",
      "Epoch 201/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0316 - acc: 0.9859 - val_loss: 0.0926 - val_acc: 0.9697\n",
      "Epoch 202/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0322 - acc: 0.9857 - val_loss: 0.0964 - val_acc: 0.9691\n",
      "Epoch 203/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0383 - acc: 0.9834 - val_loss: 0.0834 - val_acc: 0.9713\n",
      "Epoch 204/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0316 - acc: 0.9860 - val_loss: 0.0911 - val_acc: 0.9703\n",
      "Epoch 205/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0311 - acc: 0.9862 - val_loss: 0.0931 - val_acc: 0.9702\n",
      "Epoch 206/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0315 - acc: 0.9861 - val_loss: 0.0931 - val_acc: 0.9699\n",
      "Epoch 207/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0299 - acc: 0.9869 - val_loss: 0.0936 - val_acc: 0.9698\n",
      "Epoch 208/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0309 - acc: 0.9861 - val_loss: 0.0888 - val_acc: 0.9714\n",
      "Epoch 209/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0306 - acc: 0.9864 - val_loss: 0.1040 - val_acc: 0.9684\n",
      "Epoch 210/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0336 - acc: 0.9854 - val_loss: 0.0953 - val_acc: 0.9706\n",
      "Epoch 211/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0322 - acc: 0.9857 - val_loss: 0.0894 - val_acc: 0.9707\n",
      "Epoch 212/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0293 - acc: 0.9869 - val_loss: 0.0951 - val_acc: 0.9704\n",
      "Epoch 213/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0294 - acc: 0.9870 - val_loss: 0.0968 - val_acc: 0.9696\n",
      "Epoch 214/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0300 - acc: 0.9869 - val_loss: 0.0928 - val_acc: 0.9698\n",
      "Epoch 215/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0296 - acc: 0.9870 - val_loss: 0.0983 - val_acc: 0.9697\n",
      "Epoch 216/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0297 - acc: 0.9870 - val_loss: 0.0944 - val_acc: 0.9703\n",
      "Epoch 217/500\n",
      "3599/3599 [==============================] - 1s 139us/step - loss: 0.0345 - acc: 0.9850 - val_loss: 0.0939 - val_acc: 0.9700\n",
      "Epoch 218/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0328 - acc: 0.9858 - val_loss: 0.0922 - val_acc: 0.9704\n",
      "Epoch 219/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0284 - acc: 0.9876 - val_loss: 0.0985 - val_acc: 0.9715\n",
      "Epoch 220/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0266 - acc: 0.9883 - val_loss: 0.1031 - val_acc: 0.9699\n",
      "Epoch 221/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0273 - acc: 0.9880 - val_loss: 0.1031 - val_acc: 0.9705\n",
      "Epoch 222/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0294 - acc: 0.9873 - val_loss: 0.0992 - val_acc: 0.9701\n",
      "Epoch 223/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0293 - acc: 0.9871 - val_loss: 0.0988 - val_acc: 0.9707\n",
      "Epoch 224/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0354 - acc: 0.9850 - val_loss: 0.0968 - val_acc: 0.9695\n",
      "Epoch 225/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0303 - acc: 0.9868 - val_loss: 0.0943 - val_acc: 0.9703\n",
      "Epoch 226/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0281 - acc: 0.9877 - val_loss: 0.0955 - val_acc: 0.9707\n",
      "Epoch 227/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0280 - acc: 0.9877 - val_loss: 0.0992 - val_acc: 0.9701\n",
      "Epoch 228/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0270 - acc: 0.9881 - val_loss: 0.0995 - val_acc: 0.9703\n",
      "Epoch 229/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0283 - acc: 0.9875 - val_loss: 0.1050 - val_acc: 0.9696\n",
      "Epoch 230/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0307 - acc: 0.9868 - val_loss: 0.1013 - val_acc: 0.9696\n",
      "Epoch 231/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0269 - acc: 0.9883 - val_loss: 0.1042 - val_acc: 0.9701\n",
      "Epoch 232/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0271 - acc: 0.9880 - val_loss: 0.1045 - val_acc: 0.9699\n",
      "Epoch 233/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0267 - acc: 0.9884 - val_loss: 0.1087 - val_acc: 0.9695\n",
      "Epoch 234/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0255 - acc: 0.9889 - val_loss: 0.1093 - val_acc: 0.9701\n",
      "Epoch 235/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0252 - acc: 0.9890 - val_loss: 0.1089 - val_acc: 0.9696\n",
      "Epoch 236/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0284 - acc: 0.9879 - val_loss: 0.1009 - val_acc: 0.9713\n",
      "Epoch 237/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0317 - acc: 0.9865 - val_loss: 0.1093 - val_acc: 0.9679\n",
      "Epoch 238/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0281 - acc: 0.9880 - val_loss: 0.1063 - val_acc: 0.9698\n",
      "Epoch 239/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0355 - acc: 0.9855 - val_loss: 0.0953 - val_acc: 0.9700\n",
      "Epoch 240/500\n",
      "3599/3599 [==============================] - 0s 139us/step - loss: 0.0275 - acc: 0.9880 - val_loss: 0.1001 - val_acc: 0.9707\n",
      "Epoch 241/500\n",
      "3599/3599 [==============================] - 0s 138us/step - loss: 0.0238 - acc: 0.9895 - val_loss: 0.1063 - val_acc: 0.9712\n",
      "Epoch 242/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0237 - acc: 0.9897 - val_loss: 0.1169 - val_acc: 0.9683\n",
      "Epoch 243/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0232 - acc: 0.9900 - val_loss: 0.1140 - val_acc: 0.9701\n",
      "Epoch 244/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0229 - acc: 0.9900 - val_loss: 0.1152 - val_acc: 0.9699\n",
      "Epoch 245/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0253 - acc: 0.9892 - val_loss: 0.1181 - val_acc: 0.9683\n",
      "Epoch 246/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0277 - acc: 0.9881 - val_loss: 0.1116 - val_acc: 0.9699\n",
      "Epoch 247/500\n",
      "3599/3599 [==============================] - 1s 139us/step - loss: 0.0243 - acc: 0.9895 - val_loss: 0.1155 - val_acc: 0.9695\n",
      "Epoch 248/500\n",
      "3599/3599 [==============================] - 0s 138us/step - loss: 0.0242 - acc: 0.9895 - val_loss: 0.1175 - val_acc: 0.9697\n",
      "Epoch 249/500\n",
      "3599/3599 [==============================] - 1s 139us/step - loss: 0.0256 - acc: 0.9891 - val_loss: 0.1121 - val_acc: 0.9693\n",
      "Epoch 250/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0265 - acc: 0.9888 - val_loss: 0.1131 - val_acc: 0.9695\n",
      "Epoch 251/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0242 - acc: 0.9896 - val_loss: 0.1147 - val_acc: 0.9703\n",
      "Epoch 252/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0264 - acc: 0.9888 - val_loss: 0.1114 - val_acc: 0.9705\n",
      "Epoch 253/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0312 - acc: 0.9871 - val_loss: 0.1128 - val_acc: 0.9684\n",
      "Epoch 254/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0289 - acc: 0.9877 - val_loss: 0.1092 - val_acc: 0.9695\n",
      "Epoch 255/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0225 - acc: 0.9903 - val_loss: 0.1155 - val_acc: 0.9697\n",
      "Epoch 256/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0207 - acc: 0.9912 - val_loss: 0.1195 - val_acc: 0.9702\n",
      "Epoch 257/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0208 - acc: 0.9911 - val_loss: 0.1208 - val_acc: 0.9703\n",
      "Epoch 258/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0235 - acc: 0.9900 - val_loss: 0.1187 - val_acc: 0.9704\n",
      "Epoch 259/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0233 - acc: 0.9900 - val_loss: 0.1227 - val_acc: 0.9693\n",
      "Epoch 260/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0240 - acc: 0.9899 - val_loss: 0.1205 - val_acc: 0.9699\n",
      "Epoch 261/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0225 - acc: 0.9904 - val_loss: 0.1202 - val_acc: 0.9699\n",
      "Epoch 262/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0229 - acc: 0.9902 - val_loss: 0.1179 - val_acc: 0.9698\n",
      "Epoch 263/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0240 - acc: 0.9899 - val_loss: 0.1219 - val_acc: 0.9689\n",
      "Epoch 264/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0270 - acc: 0.9887 - val_loss: 0.1127 - val_acc: 0.9704\n",
      "Epoch 265/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0231 - acc: 0.9901 - val_loss: 0.1206 - val_acc: 0.9700\n",
      "Epoch 266/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0201 - acc: 0.9914 - val_loss: 0.1251 - val_acc: 0.9700\n",
      "Epoch 267/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0201 - acc: 0.9916 - val_loss: 0.1309 - val_acc: 0.9697\n",
      "Epoch 268/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0233 - acc: 0.9901 - val_loss: 0.1228 - val_acc: 0.9694\n",
      "Epoch 269/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0216 - acc: 0.9908 - val_loss: 0.1267 - val_acc: 0.9697\n",
      "Epoch 270/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0219 - acc: 0.9909 - val_loss: 0.1274 - val_acc: 0.9691\n",
      "Epoch 271/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0218 - acc: 0.9908 - val_loss: 0.1313 - val_acc: 0.9687\n",
      "Epoch 272/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0215 - acc: 0.9909 - val_loss: 0.1279 - val_acc: 0.9695\n",
      "Epoch 273/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0263 - acc: 0.9891 - val_loss: 0.1257 - val_acc: 0.9683\n",
      "Epoch 274/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0258 - acc: 0.9892 - val_loss: 0.1221 - val_acc: 0.9695\n",
      "Epoch 275/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0221 - acc: 0.9907 - val_loss: 0.1188 - val_acc: 0.9703\n",
      "Epoch 276/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0201 - acc: 0.9914 - val_loss: 0.1258 - val_acc: 0.9700\n",
      "Epoch 277/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0196 - acc: 0.9918 - val_loss: 0.1260 - val_acc: 0.9700\n",
      "Epoch 278/500\n",
      "3599/3599 [==============================] - 1s 150us/step - loss: 0.0210 - acc: 0.9911 - val_loss: 0.1246 - val_acc: 0.9702\n",
      "Epoch 279/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0193 - acc: 0.9919 - val_loss: 0.1320 - val_acc: 0.9700\n",
      "Epoch 280/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0200 - acc: 0.9916 - val_loss: 0.1365 - val_acc: 0.9698\n",
      "Epoch 281/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0223 - acc: 0.9906 - val_loss: 0.1306 - val_acc: 0.9697\n",
      "Epoch 282/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0217 - acc: 0.9909 - val_loss: 0.1352 - val_acc: 0.9686\n",
      "Epoch 283/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0220 - acc: 0.9907 - val_loss: 0.1359 - val_acc: 0.9689\n",
      "Epoch 284/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0240 - acc: 0.9900 - val_loss: 0.1351 - val_acc: 0.9685\n",
      "Epoch 285/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0179 - acc: 0.9924 - val_loss: 0.1334 - val_acc: 0.9704\n",
      "Epoch 286/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0182 - acc: 0.9922 - val_loss: 0.1376 - val_acc: 0.9704\n",
      "Epoch 287/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0167 - acc: 0.9930 - val_loss: 0.1367 - val_acc: 0.9701\n",
      "Epoch 288/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0184 - acc: 0.9924 - val_loss: 0.1367 - val_acc: 0.9695\n",
      "Epoch 289/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0178 - acc: 0.9924 - val_loss: 0.1356 - val_acc: 0.9704\n",
      "Epoch 290/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0209 - acc: 0.9914 - val_loss: 0.1345 - val_acc: 0.9699\n",
      "Epoch 291/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0213 - acc: 0.9913 - val_loss: 0.1326 - val_acc: 0.9699\n",
      "Epoch 292/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0254 - acc: 0.9899 - val_loss: 0.1378 - val_acc: 0.9663\n",
      "Epoch 293/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0354 - acc: 0.9861 - val_loss: 0.1202 - val_acc: 0.9692\n",
      "Epoch 294/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0246 - acc: 0.9899 - val_loss: 0.1168 - val_acc: 0.9704\n",
      "Epoch 295/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0186 - acc: 0.9923 - val_loss: 0.1266 - val_acc: 0.9705\n",
      "Epoch 296/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0150 - acc: 0.9938 - val_loss: 0.1374 - val_acc: 0.9704\n",
      "Epoch 297/500\n",
      "3599/3599 [==============================] - 1s 139us/step - loss: 0.0145 - acc: 0.9940 - val_loss: 0.1387 - val_acc: 0.9706\n",
      "Epoch 298/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0165 - acc: 0.9931 - val_loss: 0.1500 - val_acc: 0.9687\n",
      "Epoch 299/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0208 - acc: 0.9914 - val_loss: 0.1365 - val_acc: 0.9693\n",
      "Epoch 300/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0308 - acc: 0.9882 - val_loss: 0.1444 - val_acc: 0.9654\n",
      "Epoch 301/500\n",
      "3599/3599 [==============================] - 1s 139us/step - loss: 0.0276 - acc: 0.9888 - val_loss: 0.1214 - val_acc: 0.9705\n",
      "Epoch 302/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0174 - acc: 0.9928 - val_loss: 0.1306 - val_acc: 0.9705\n",
      "Epoch 303/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0145 - acc: 0.9941 - val_loss: 0.1382 - val_acc: 0.9713\n",
      "Epoch 304/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0143 - acc: 0.9942 - val_loss: 0.1465 - val_acc: 0.9707\n",
      "Epoch 305/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0151 - acc: 0.9938 - val_loss: 0.1501 - val_acc: 0.9701\n",
      "Epoch 306/500\n",
      "3599/3599 [==============================] - 1s 139us/step - loss: 0.0194 - acc: 0.9920 - val_loss: 0.1478 - val_acc: 0.9694\n",
      "Epoch 307/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0193 - acc: 0.9921 - val_loss: 0.1462 - val_acc: 0.9691\n",
      "Epoch 308/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0194 - acc: 0.9920 - val_loss: 0.1444 - val_acc: 0.9701\n",
      "Epoch 309/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0195 - acc: 0.9919 - val_loss: 0.1406 - val_acc: 0.9697\n",
      "Epoch 310/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0175 - acc: 0.9927 - val_loss: 0.1468 - val_acc: 0.9697\n",
      "Epoch 311/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0213 - acc: 0.9916 - val_loss: 0.1378 - val_acc: 0.9690\n",
      "Epoch 312/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0309 - acc: 0.9880 - val_loss: 0.1228 - val_acc: 0.9691\n",
      "Epoch 313/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0204 - acc: 0.9915 - val_loss: 0.1358 - val_acc: 0.9699\n",
      "Epoch 314/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0150 - acc: 0.9939 - val_loss: 0.1411 - val_acc: 0.9702\n",
      "Epoch 315/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0146 - acc: 0.9942 - val_loss: 0.1500 - val_acc: 0.9703\n",
      "Epoch 316/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0131 - acc: 0.9946 - val_loss: 0.1533 - val_acc: 0.9704\n",
      "Epoch 317/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0123 - acc: 0.9949 - val_loss: 0.1635 - val_acc: 0.9701\n",
      "Epoch 318/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0181 - acc: 0.9928 - val_loss: 0.1505 - val_acc: 0.9688\n",
      "Epoch 319/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0212 - acc: 0.9914 - val_loss: 0.1425 - val_acc: 0.9693\n",
      "Epoch 320/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0210 - acc: 0.9915 - val_loss: 0.1409 - val_acc: 0.9698\n",
      "Epoch 321/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0183 - acc: 0.9926 - val_loss: 0.1423 - val_acc: 0.9702\n",
      "Epoch 322/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0173 - acc: 0.9930 - val_loss: 0.1493 - val_acc: 0.9697\n",
      "Epoch 323/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0186 - acc: 0.9928 - val_loss: 0.1434 - val_acc: 0.9692\n",
      "Epoch 324/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0167 - acc: 0.9932 - val_loss: 0.1452 - val_acc: 0.9703\n",
      "Epoch 325/500\n",
      "3599/3599 [==============================] - 1s 148us/step - loss: 0.0140 - acc: 0.9943 - val_loss: 0.1589 - val_acc: 0.9686\n",
      "Epoch 326/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0133 - acc: 0.9945 - val_loss: 0.1623 - val_acc: 0.9699\n",
      "Epoch 327/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0186 - acc: 0.9928 - val_loss: 0.1478 - val_acc: 0.9694\n",
      "Epoch 328/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0179 - acc: 0.9928 - val_loss: 0.1557 - val_acc: 0.9692\n",
      "Epoch 329/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0152 - acc: 0.9937 - val_loss: 0.1545 - val_acc: 0.9695\n",
      "Epoch 330/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0142 - acc: 0.9942 - val_loss: 0.1535 - val_acc: 0.9696\n",
      "Epoch 331/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0161 - acc: 0.9935 - val_loss: 0.1549 - val_acc: 0.9697\n",
      "Epoch 332/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0164 - acc: 0.9933 - val_loss: 0.1557 - val_acc: 0.9690\n",
      "Epoch 333/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0171 - acc: 0.9932 - val_loss: 0.1605 - val_acc: 0.9679\n",
      "Epoch 334/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0236 - acc: 0.9910 - val_loss: 0.1414 - val_acc: 0.9690\n",
      "Epoch 335/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0165 - acc: 0.9934 - val_loss: 0.1546 - val_acc: 0.9691\n",
      "Epoch 336/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0132 - acc: 0.9946 - val_loss: 0.1508 - val_acc: 0.9701\n",
      "Epoch 337/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0121 - acc: 0.9951 - val_loss: 0.1583 - val_acc: 0.9698\n",
      "Epoch 338/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0120 - acc: 0.9953 - val_loss: 0.1682 - val_acc: 0.9696\n",
      "Epoch 339/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0133 - acc: 0.9947 - val_loss: 0.1765 - val_acc: 0.9686\n",
      "Epoch 340/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0162 - acc: 0.9935 - val_loss: 0.1560 - val_acc: 0.9692\n",
      "Epoch 341/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0201 - acc: 0.9921 - val_loss: 0.1622 - val_acc: 0.9671\n",
      "Epoch 342/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0217 - acc: 0.9912 - val_loss: 0.1470 - val_acc: 0.9699\n",
      "Epoch 343/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0180 - acc: 0.9927 - val_loss: 0.1446 - val_acc: 0.9708\n",
      "Epoch 344/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0128 - acc: 0.9948 - val_loss: 0.1570 - val_acc: 0.9696\n",
      "Epoch 345/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0120 - acc: 0.9952 - val_loss: 0.1611 - val_acc: 0.9699\n",
      "Epoch 346/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0117 - acc: 0.9955 - val_loss: 0.1701 - val_acc: 0.9692\n",
      "Epoch 347/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0130 - acc: 0.9948 - val_loss: 0.1704 - val_acc: 0.9696\n",
      "Epoch 348/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0216 - acc: 0.9918 - val_loss: 0.1533 - val_acc: 0.9690\n",
      "Epoch 349/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0216 - acc: 0.9917 - val_loss: 0.1503 - val_acc: 0.9693\n",
      "Epoch 350/500\n",
      "3599/3599 [==============================] - 1s 151us/step - loss: 0.0179 - acc: 0.9928 - val_loss: 0.1499 - val_acc: 0.9686\n",
      "Epoch 351/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0144 - acc: 0.9942 - val_loss: 0.1572 - val_acc: 0.9696\n",
      "Epoch 352/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0129 - acc: 0.9949 - val_loss: 0.1626 - val_acc: 0.9692\n",
      "Epoch 353/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0110 - acc: 0.9956 - val_loss: 0.1634 - val_acc: 0.9703\n",
      "Epoch 354/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0099 - acc: 0.9961 - val_loss: 0.1696 - val_acc: 0.9704\n",
      "Epoch 355/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0110 - acc: 0.9957 - val_loss: 0.1791 - val_acc: 0.9689\n",
      "Epoch 356/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0190 - acc: 0.9927 - val_loss: 0.1724 - val_acc: 0.9673\n",
      "Epoch 357/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0215 - acc: 0.9917 - val_loss: 0.1558 - val_acc: 0.9689\n",
      "Epoch 358/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0223 - acc: 0.9916 - val_loss: 0.1487 - val_acc: 0.9685\n",
      "Epoch 359/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0177 - acc: 0.9931 - val_loss: 0.1515 - val_acc: 0.9684\n",
      "Epoch 360/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0129 - acc: 0.9948 - val_loss: 0.1594 - val_acc: 0.9697\n",
      "Epoch 361/500\n",
      "3599/3599 [==============================] - 0s 139us/step - loss: 0.0105 - acc: 0.9959 - val_loss: 0.1678 - val_acc: 0.9697\n",
      "Epoch 362/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0091 - acc: 0.9964 - val_loss: 0.1722 - val_acc: 0.9698\n",
      "Epoch 363/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0094 - acc: 0.9963 - val_loss: 0.1803 - val_acc: 0.9693\n",
      "Epoch 364/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0114 - acc: 0.9954 - val_loss: 0.1831 - val_acc: 0.9691\n",
      "Epoch 365/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0134 - acc: 0.9947 - val_loss: 0.1870 - val_acc: 0.9679\n",
      "Epoch 366/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0174 - acc: 0.9933 - val_loss: 0.1637 - val_acc: 0.9685\n",
      "Epoch 367/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0289 - acc: 0.9897 - val_loss: 0.1448 - val_acc: 0.9691\n",
      "Epoch 368/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0145 - acc: 0.9943 - val_loss: 0.1629 - val_acc: 0.9694\n",
      "Epoch 369/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0100 - acc: 0.9962 - val_loss: 0.1710 - val_acc: 0.9698\n",
      "Epoch 370/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0083 - acc: 0.9968 - val_loss: 0.1847 - val_acc: 0.9695\n",
      "Epoch 371/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0071 - acc: 0.9972 - val_loss: 0.1863 - val_acc: 0.9702\n",
      "Epoch 372/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0098 - acc: 0.9962 - val_loss: 0.1889 - val_acc: 0.9694\n",
      "Epoch 373/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0168 - acc: 0.9936 - val_loss: 0.1837 - val_acc: 0.9673\n",
      "Epoch 374/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0190 - acc: 0.9927 - val_loss: 0.1691 - val_acc: 0.9680\n",
      "Epoch 375/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0202 - acc: 0.9924 - val_loss: 0.1613 - val_acc: 0.9690\n",
      "Epoch 376/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0162 - acc: 0.9937 - val_loss: 0.1596 - val_acc: 0.9700\n",
      "Epoch 377/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0121 - acc: 0.9953 - val_loss: 0.1747 - val_acc: 0.9693\n",
      "Epoch 378/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0133 - acc: 0.9949 - val_loss: 0.1753 - val_acc: 0.9686\n",
      "Epoch 379/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0148 - acc: 0.9943 - val_loss: 0.1715 - val_acc: 0.9687\n",
      "Epoch 380/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0117 - acc: 0.9955 - val_loss: 0.1727 - val_acc: 0.9695\n",
      "Epoch 381/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0114 - acc: 0.9956 - val_loss: 0.1797 - val_acc: 0.9696\n",
      "Epoch 382/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0115 - acc: 0.9955 - val_loss: 0.1787 - val_acc: 0.9699\n",
      "Epoch 383/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0134 - acc: 0.9949 - val_loss: 0.1867 - val_acc: 0.9684\n",
      "Epoch 384/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0190 - acc: 0.9931 - val_loss: 0.1726 - val_acc: 0.9689\n",
      "Epoch 385/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0164 - acc: 0.9939 - val_loss: 0.1709 - val_acc: 0.9697\n",
      "Epoch 386/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0182 - acc: 0.9930 - val_loss: 0.1654 - val_acc: 0.9685\n",
      "Epoch 387/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0110 - acc: 0.9958 - val_loss: 0.1761 - val_acc: 0.9690\n",
      "Epoch 388/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0097 - acc: 0.9963 - val_loss: 0.1803 - val_acc: 0.9694\n",
      "Epoch 389/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0095 - acc: 0.9963 - val_loss: 0.1857 - val_acc: 0.9697\n",
      "Epoch 390/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0089 - acc: 0.9966 - val_loss: 0.1950 - val_acc: 0.9684\n",
      "Epoch 391/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0092 - acc: 0.9965 - val_loss: 0.1954 - val_acc: 0.9693\n",
      "Epoch 392/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0127 - acc: 0.9953 - val_loss: 0.1791 - val_acc: 0.9693\n",
      "Epoch 393/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0180 - acc: 0.9932 - val_loss: 0.1793 - val_acc: 0.9676\n",
      "Epoch 394/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0372 - acc: 0.9874 - val_loss: 0.1399 - val_acc: 0.9681\n",
      "Epoch 395/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0190 - acc: 0.9927 - val_loss: 0.1490 - val_acc: 0.9692\n",
      "Epoch 396/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0114 - acc: 0.9957 - val_loss: 0.1622 - val_acc: 0.9705\n",
      "Epoch 397/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0075 - acc: 0.9973 - val_loss: 0.1716 - val_acc: 0.9704\n",
      "Epoch 398/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0063 - acc: 0.9978 - val_loss: 0.1876 - val_acc: 0.9704\n",
      "Epoch 399/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.1970 - val_acc: 0.9696\n",
      "Epoch 400/500\n",
      "3599/3599 [==============================] - 1s 148us/step - loss: 0.0072 - acc: 0.9973 - val_loss: 0.1972 - val_acc: 0.9701\n",
      "Epoch 401/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0095 - acc: 0.9964 - val_loss: 0.1941 - val_acc: 0.9693\n",
      "Epoch 402/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0172 - acc: 0.9936 - val_loss: 0.1889 - val_acc: 0.9677\n",
      "Epoch 403/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0196 - acc: 0.9928 - val_loss: 0.1783 - val_acc: 0.9673\n",
      "Epoch 404/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0182 - acc: 0.9931 - val_loss: 0.1690 - val_acc: 0.9688\n",
      "Epoch 405/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0156 - acc: 0.9941 - val_loss: 0.1719 - val_acc: 0.9688\n",
      "Epoch 406/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0123 - acc: 0.9953 - val_loss: 0.1757 - val_acc: 0.9696\n",
      "Epoch 407/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0088 - acc: 0.9967 - val_loss: 0.1859 - val_acc: 0.9698\n",
      "Epoch 408/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0056 - acc: 0.9980 - val_loss: 0.1932 - val_acc: 0.9700\n",
      "Epoch 409/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0055 - acc: 0.9980 - val_loss: 0.2029 - val_acc: 0.9699\n",
      "Epoch 410/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0076 - acc: 0.9971 - val_loss: 0.2060 - val_acc: 0.9691\n",
      "Epoch 411/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0226 - acc: 0.9923 - val_loss: 0.1954 - val_acc: 0.9650\n",
      "Epoch 412/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0332 - acc: 0.9883 - val_loss: 0.1486 - val_acc: 0.9680\n",
      "Epoch 413/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0167 - acc: 0.9937 - val_loss: 0.1547 - val_acc: 0.9700\n",
      "Epoch 414/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0104 - acc: 0.9961 - val_loss: 0.1712 - val_acc: 0.9700\n",
      "Epoch 415/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0069 - acc: 0.9976 - val_loss: 0.1871 - val_acc: 0.9702\n",
      "Epoch 416/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.1960 - val_acc: 0.9696\n",
      "Epoch 417/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0052 - acc: 0.9981 - val_loss: 0.1984 - val_acc: 0.9701\n",
      "Epoch 418/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.2096 - val_acc: 0.9703\n",
      "Epoch 419/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0078 - acc: 0.9971 - val_loss: 0.2060 - val_acc: 0.9695\n",
      "Epoch 420/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0221 - acc: 0.9922 - val_loss: 0.1736 - val_acc: 0.9679\n",
      "Epoch 421/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0221 - acc: 0.9916 - val_loss: 0.1688 - val_acc: 0.9678\n",
      "Epoch 422/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0140 - acc: 0.9947 - val_loss: 0.1665 - val_acc: 0.9691\n",
      "Epoch 423/500\n",
      "3599/3599 [==============================] - 1s 140us/step - loss: 0.0092 - acc: 0.9966 - val_loss: 0.1795 - val_acc: 0.9697\n",
      "Epoch 424/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0076 - acc: 0.9971 - val_loss: 0.1880 - val_acc: 0.9699\n",
      "Epoch 425/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0072 - acc: 0.9974 - val_loss: 0.1920 - val_acc: 0.9698\n",
      "Epoch 426/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0075 - acc: 0.9973 - val_loss: 0.2047 - val_acc: 0.9690\n",
      "Epoch 427/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0098 - acc: 0.9964 - val_loss: 0.2012 - val_acc: 0.9685\n",
      "Epoch 428/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0226 - acc: 0.9923 - val_loss: 0.1816 - val_acc: 0.9664\n",
      "Epoch 429/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0280 - acc: 0.9899 - val_loss: 0.1505 - val_acc: 0.9689\n",
      "Epoch 430/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0146 - acc: 0.9946 - val_loss: 0.1598 - val_acc: 0.9699\n",
      "Epoch 431/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0086 - acc: 0.9969 - val_loss: 0.1713 - val_acc: 0.9707\n",
      "Epoch 432/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.1858 - val_acc: 0.9706\n",
      "Epoch 433/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0041 - acc: 0.9986 - val_loss: 0.1994 - val_acc: 0.9708\n",
      "Epoch 434/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.2062 - val_acc: 0.9710\n",
      "Epoch 435/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0095 - acc: 0.9966 - val_loss: 0.2014 - val_acc: 0.9682\n",
      "Epoch 436/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0262 - acc: 0.9911 - val_loss: 0.1657 - val_acc: 0.9684\n",
      "Epoch 437/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0237 - acc: 0.9914 - val_loss: 0.1529 - val_acc: 0.9685\n",
      "Epoch 438/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0133 - acc: 0.9950 - val_loss: 0.1637 - val_acc: 0.9702\n",
      "Epoch 439/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0074 - acc: 0.9974 - val_loss: 0.1797 - val_acc: 0.9706\n",
      "Epoch 440/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0060 - acc: 0.9980 - val_loss: 0.1902 - val_acc: 0.9707\n",
      "Epoch 441/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0049 - acc: 0.9983 - val_loss: 0.1986 - val_acc: 0.9702\n",
      "Epoch 442/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0077 - acc: 0.9972 - val_loss: 0.1954 - val_acc: 0.9698\n",
      "Epoch 443/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0165 - acc: 0.9942 - val_loss: 0.1989 - val_acc: 0.9661\n",
      "Epoch 444/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0236 - acc: 0.9916 - val_loss: 0.1660 - val_acc: 0.9683\n",
      "Epoch 445/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0117 - acc: 0.9956 - val_loss: 0.1697 - val_acc: 0.9697\n",
      "Epoch 446/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0063 - acc: 0.9978 - val_loss: 0.1882 - val_acc: 0.9699\n",
      "Epoch 447/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.1935 - val_acc: 0.9706\n",
      "Epoch 448/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.1974 - val_acc: 0.9709\n",
      "Epoch 449/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0041 - acc: 0.9986 - val_loss: 0.2098 - val_acc: 0.9704\n",
      "Epoch 450/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0100 - acc: 0.9965 - val_loss: 0.2094 - val_acc: 0.9682\n",
      "Epoch 451/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0199 - acc: 0.9929 - val_loss: 0.1722 - val_acc: 0.9690\n",
      "Epoch 452/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0213 - acc: 0.9924 - val_loss: 0.1664 - val_acc: 0.9685\n",
      "Epoch 453/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0151 - acc: 0.9943 - val_loss: 0.1682 - val_acc: 0.9704\n",
      "Epoch 454/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0080 - acc: 0.9971 - val_loss: 0.1808 - val_acc: 0.9698\n",
      "Epoch 455/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.1913 - val_acc: 0.9701\n",
      "Epoch 456/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0060 - acc: 0.9978 - val_loss: 0.2029 - val_acc: 0.9695\n",
      "Epoch 457/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0065 - acc: 0.9976 - val_loss: 0.2054 - val_acc: 0.9699\n",
      "Epoch 458/500\n",
      "3599/3599 [==============================] - 1s 146us/step - loss: 0.0072 - acc: 0.9974 - val_loss: 0.2053 - val_acc: 0.9701\n",
      "Epoch 459/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0111 - acc: 0.9962 - val_loss: 0.2129 - val_acc: 0.9683\n",
      "Epoch 460/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0222 - acc: 0.9924 - val_loss: 0.1784 - val_acc: 0.9678\n",
      "Epoch 461/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0236 - acc: 0.9917 - val_loss: 0.1593 - val_acc: 0.9687\n",
      "Epoch 462/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0172 - acc: 0.9934 - val_loss: 0.1679 - val_acc: 0.9690\n",
      "Epoch 463/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0081 - acc: 0.9970 - val_loss: 0.1769 - val_acc: 0.9703\n",
      "Epoch 464/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.1943 - val_acc: 0.9697\n",
      "Epoch 465/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.2048 - val_acc: 0.9701\n",
      "Epoch 466/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.2110 - val_acc: 0.9705\n",
      "Epoch 467/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.2171 - val_acc: 0.9705\n",
      "Epoch 468/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0089 - acc: 0.9968 - val_loss: 0.2115 - val_acc: 0.9684\n",
      "Epoch 469/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0446 - acc: 0.9866 - val_loss: 0.1507 - val_acc: 0.9645\n",
      "Epoch 470/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0288 - acc: 0.9891 - val_loss: 0.1354 - val_acc: 0.9693\n",
      "Epoch 471/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0120 - acc: 0.9956 - val_loss: 0.1580 - val_acc: 0.9696\n",
      "Epoch 472/500\n",
      "3599/3599 [==============================] - 1s 147us/step - loss: 0.0078 - acc: 0.9973 - val_loss: 0.1711 - val_acc: 0.9700\n",
      "Epoch 473/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0049 - acc: 0.9985 - val_loss: 0.1806 - val_acc: 0.9709\n",
      "Epoch 474/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.1953 - val_acc: 0.9698\n",
      "Epoch 475/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.2042 - val_acc: 0.9709\n",
      "Epoch 476/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.2112 - val_acc: 0.9705\n",
      "Epoch 477/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.2209 - val_acc: 0.9694\n",
      "Epoch 478/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0203 - acc: 0.9932 - val_loss: 0.1796 - val_acc: 0.9676\n",
      "Epoch 479/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0198 - acc: 0.9929 - val_loss: 0.1622 - val_acc: 0.9684\n",
      "Epoch 480/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0130 - acc: 0.9951 - val_loss: 0.1781 - val_acc: 0.9690\n",
      "Epoch 481/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0094 - acc: 0.9965 - val_loss: 0.1849 - val_acc: 0.9695\n",
      "Epoch 482/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.1947 - val_acc: 0.9701\n",
      "Epoch 483/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.2015 - val_acc: 0.9705\n",
      "Epoch 484/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0132 - acc: 0.9957 - val_loss: 0.1874 - val_acc: 0.9683\n",
      "Epoch 485/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0197 - acc: 0.9928 - val_loss: 0.1796 - val_acc: 0.9683\n",
      "Epoch 486/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0159 - acc: 0.9942 - val_loss: 0.1691 - val_acc: 0.9700\n",
      "Epoch 487/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0098 - acc: 0.9964 - val_loss: 0.1888 - val_acc: 0.9688\n",
      "Epoch 488/500\n",
      "3599/3599 [==============================] - 1s 143us/step - loss: 0.0098 - acc: 0.9964 - val_loss: 0.1886 - val_acc: 0.9689\n",
      "Epoch 489/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0128 - acc: 0.9954 - val_loss: 0.1834 - val_acc: 0.9702\n",
      "Epoch 490/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0104 - acc: 0.9962 - val_loss: 0.1890 - val_acc: 0.9694\n",
      "Epoch 491/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0067 - acc: 0.9976 - val_loss: 0.1965 - val_acc: 0.9696\n",
      "Epoch 492/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.2035 - val_acc: 0.9700\n",
      "Epoch 493/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.2075 - val_acc: 0.9709\n",
      "Epoch 494/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0067 - acc: 0.9977 - val_loss: 0.2167 - val_acc: 0.9695\n",
      "Epoch 495/500\n",
      "3599/3599 [==============================] - 1s 144us/step - loss: 0.0132 - acc: 0.9953 - val_loss: 0.2031 - val_acc: 0.9679\n",
      "Epoch 496/500\n",
      "3599/3599 [==============================] - 1s 145us/step - loss: 0.0233 - acc: 0.9923 - val_loss: 0.1815 - val_acc: 0.9671\n",
      "Epoch 497/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0183 - acc: 0.9934 - val_loss: 0.1713 - val_acc: 0.9695\n",
      "Epoch 498/500\n",
      "3599/3599 [==============================] - 1s 142us/step - loss: 0.0102 - acc: 0.9962 - val_loss: 0.1742 - val_acc: 0.9699\n",
      "Epoch 499/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0064 - acc: 0.9978 - val_loss: 0.1855 - val_acc: 0.9705\n",
      "Epoch 500/500\n",
      "3599/3599 [==============================] - 1s 141us/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.1925 - val_acc: 0.9715\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(np.array(df_train[\"in\"].values.tolist()), np.array(df_train[\"out\"].values.tolist()), epochs=500, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 35us/step\n",
      "Custo: 0.19845810985565185\n",
      "Acurácia: 0.971\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model2, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 acertos 7.4 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>numero</th>\n",
       "      <th>pred</th>\n",
       "      <th>romano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3208</td>\n",
       "      <td>MMMCCIX</td>\n",
       "      <td>MMMCCVIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>4994</td>\n",
       "      <td>MMMMCMXCVI</td>\n",
       "      <td>MMMMCMXCIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3997</td>\n",
       "      <td>MMMCMXCII</td>\n",
       "      <td>MMMCMXCVII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>2573</td>\n",
       "      <td>MMDLXXII</td>\n",
       "      <td>MMDLXXIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>4184</td>\n",
       "      <td>MMMMCLXXXV</td>\n",
       "      <td>MMMMCLXXXIV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match  numero        pred       romano\n",
       "0  False    3208     MMMCCIX    MMMCCVIII\n",
       "1  False    4994  MMMMCMXCVI   MMMMCMXCIV\n",
       "2  False    3997   MMMCMXCII   MMMCMXCVII\n",
       "3  False    2573    MMDLXXII    MMDLXXIII\n",
       "4  False    4184  MMMMCLXXXV  MMMMCLXXXIV"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_p500 = evaluate_algorisms(model2, df_test)\n",
    "df2_p500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfit!!\n",
    "Dessa vez o modelo consegue acertar todo o conjunto de treino mas não o conjunto de testes, o modelo apenas decorou os algarismos do conjunto de treino mas não consegue generalizar o problema. Dizemos que esse modelo possui uma grande variância e está em regime de **overfit**.\n",
    "\n",
    "## Terceira tentativa\n",
    "Por último, vamos tentar uma rede com 4 camadas ocultas, mas com mais nós em cada camada para extrair mais características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 1024)              14336     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               32896     \n",
      "=================================================================\n",
      "Total params: 703,360\n",
      "Trainable params: 703,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(units=1024, activation='relu', input_dim=13))\n",
    "model3.add(Dense(units=512, activation='relu'))\n",
    "model3.add(Dense(units=256, activation='relu'))\n",
    "model3.add(Dense(units=128, activation='sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3599 samples, validate on 400 samples\n",
      "Epoch 1/120\n",
      "3599/3599 [==============================] - 1s 309us/step - loss: 0.2134 - acc: 0.9210 - val_loss: 0.1471 - val_acc: 0.9404\n",
      "Epoch 2/120\n",
      "3599/3599 [==============================] - 1s 213us/step - loss: 0.1342 - acc: 0.9449 - val_loss: 0.1305 - val_acc: 0.9467\n",
      "Epoch 3/120\n",
      "3599/3599 [==============================] - 1s 213us/step - loss: 0.1207 - acc: 0.9505 - val_loss: 0.1179 - val_acc: 0.9518\n",
      "Epoch 4/120\n",
      "3599/3599 [==============================] - 1s 210us/step - loss: 0.1105 - acc: 0.9543 - val_loss: 0.1095 - val_acc: 0.9542\n",
      "Epoch 5/120\n",
      "3599/3599 [==============================] - 1s 212us/step - loss: 0.1034 - acc: 0.9569 - val_loss: 0.1049 - val_acc: 0.9561\n",
      "Epoch 6/120\n",
      "3599/3599 [==============================] - 1s 210us/step - loss: 0.0987 - acc: 0.9586 - val_loss: 0.1004 - val_acc: 0.9573\n",
      "Epoch 7/120\n",
      "3599/3599 [==============================] - 1s 211us/step - loss: 0.0946 - acc: 0.9605 - val_loss: 0.0983 - val_acc: 0.9579\n",
      "Epoch 8/120\n",
      "3599/3599 [==============================] - 1s 215us/step - loss: 0.0913 - acc: 0.9612 - val_loss: 0.0939 - val_acc: 0.9604\n",
      "Epoch 9/120\n",
      "3599/3599 [==============================] - 1s 209us/step - loss: 0.0879 - acc: 0.9629 - val_loss: 0.0934 - val_acc: 0.9600\n",
      "Epoch 10/120\n",
      "3599/3599 [==============================] - 1s 213us/step - loss: 0.0851 - acc: 0.9639 - val_loss: 0.0885 - val_acc: 0.9626\n",
      "Epoch 11/120\n",
      "3599/3599 [==============================] - 1s 212us/step - loss: 0.0814 - acc: 0.9654 - val_loss: 0.0866 - val_acc: 0.9634\n",
      "Epoch 12/120\n",
      "3599/3599 [==============================] - 1s 210us/step - loss: 0.0787 - acc: 0.9664 - val_loss: 0.0834 - val_acc: 0.9648\n",
      "Epoch 13/120\n",
      "3599/3599 [==============================] - 1s 212us/step - loss: 0.0765 - acc: 0.9671 - val_loss: 0.0811 - val_acc: 0.9657\n",
      "Epoch 14/120\n",
      "3599/3599 [==============================] - 1s 214us/step - loss: 0.0726 - acc: 0.9690 - val_loss: 0.0809 - val_acc: 0.9649\n",
      "Epoch 15/120\n",
      "3599/3599 [==============================] - 1s 212us/step - loss: 0.0707 - acc: 0.9695 - val_loss: 0.0754 - val_acc: 0.9675\n",
      "Epoch 16/120\n",
      "3599/3599 [==============================] - 1s 211us/step - loss: 0.0683 - acc: 0.9707 - val_loss: 0.0745 - val_acc: 0.9678\n",
      "Epoch 17/120\n",
      "3599/3599 [==============================] - 1s 212us/step - loss: 0.0670 - acc: 0.9708 - val_loss: 0.0729 - val_acc: 0.9688\n",
      "Epoch 18/120\n",
      "3599/3599 [==============================] - 1s 211us/step - loss: 0.0642 - acc: 0.9722 - val_loss: 0.0750 - val_acc: 0.9678\n",
      "Epoch 19/120\n",
      "3599/3599 [==============================] - 1s 211us/step - loss: 0.0631 - acc: 0.9726 - val_loss: 0.0714 - val_acc: 0.9703\n",
      "Epoch 20/120\n",
      "3599/3599 [==============================] - 1s 214us/step - loss: 0.0613 - acc: 0.9732 - val_loss: 0.0701 - val_acc: 0.9703\n",
      "Epoch 21/120\n",
      "3599/3599 [==============================] - 1s 215us/step - loss: 0.0600 - acc: 0.9738 - val_loss: 0.0682 - val_acc: 0.9699\n",
      "Epoch 22/120\n",
      "3599/3599 [==============================] - 1s 209us/step - loss: 0.0591 - acc: 0.9742 - val_loss: 0.0668 - val_acc: 0.9712\n",
      "Epoch 23/120\n",
      "3599/3599 [==============================] - 1s 211us/step - loss: 0.0573 - acc: 0.9748 - val_loss: 0.0667 - val_acc: 0.9716\n",
      "Epoch 24/120\n",
      "3599/3599 [==============================] - 1s 210us/step - loss: 0.0561 - acc: 0.9752 - val_loss: 0.0665 - val_acc: 0.9715\n",
      "Epoch 25/120\n",
      "3599/3599 [==============================] - 1s 212us/step - loss: 0.0551 - acc: 0.9755 - val_loss: 0.0641 - val_acc: 0.9727\n",
      "Epoch 26/120\n",
      "3599/3599 [==============================] - 1s 215us/step - loss: 0.0537 - acc: 0.9763 - val_loss: 0.0634 - val_acc: 0.9724\n",
      "Epoch 27/120\n",
      "3599/3599 [==============================] - 1s 213us/step - loss: 0.0523 - acc: 0.9768 - val_loss: 0.0626 - val_acc: 0.9739\n",
      "Epoch 28/120\n",
      "3599/3599 [==============================] - 1s 210us/step - loss: 0.0514 - acc: 0.9771 - val_loss: 0.0619 - val_acc: 0.9737\n",
      "Epoch 29/120\n",
      "3599/3599 [==============================] - 1s 214us/step - loss: 0.0494 - acc: 0.9781 - val_loss: 0.0613 - val_acc: 0.9737\n",
      "Epoch 30/120\n",
      "3599/3599 [==============================] - 1s 211us/step - loss: 0.0487 - acc: 0.9782 - val_loss: 0.0598 - val_acc: 0.9744\n",
      "Epoch 31/120\n",
      "3599/3599 [==============================] - 1s 217us/step - loss: 0.0474 - acc: 0.9790 - val_loss: 0.0582 - val_acc: 0.9748\n",
      "Epoch 32/120\n",
      "3599/3599 [==============================] - 1s 225us/step - loss: 0.0468 - acc: 0.9793 - val_loss: 0.0573 - val_acc: 0.9753\n",
      "Epoch 33/120\n",
      "3599/3599 [==============================] - 1s 218us/step - loss: 0.0442 - acc: 0.9807 - val_loss: 0.0570 - val_acc: 0.9754\n",
      "Epoch 34/120\n",
      "3599/3599 [==============================] - 1s 210us/step - loss: 0.0435 - acc: 0.9811 - val_loss: 0.0550 - val_acc: 0.9769\n",
      "Epoch 35/120\n",
      "3599/3599 [==============================] - 1s 213us/step - loss: 0.0417 - acc: 0.9819 - val_loss: 0.0576 - val_acc: 0.9760\n",
      "Epoch 36/120\n",
      "3599/3599 [==============================] - 1s 214us/step - loss: 0.0400 - acc: 0.9828 - val_loss: 0.0559 - val_acc: 0.9773\n",
      "Epoch 37/120\n",
      "3599/3599 [==============================] - 1s 211us/step - loss: 0.0383 - acc: 0.9837 - val_loss: 0.0539 - val_acc: 0.9774\n",
      "Epoch 38/120\n",
      "3599/3599 [==============================] - 1s 215us/step - loss: 0.0367 - acc: 0.9844 - val_loss: 0.0510 - val_acc: 0.9787\n",
      "Epoch 39/120\n",
      "3599/3599 [==============================] - 1s 210us/step - loss: 0.0347 - acc: 0.9853 - val_loss: 0.0515 - val_acc: 0.9796\n",
      "Epoch 40/120\n",
      "3599/3599 [==============================] - 1s 217us/step - loss: 0.0331 - acc: 0.9861 - val_loss: 0.0486 - val_acc: 0.9807\n",
      "Epoch 41/120\n",
      "3599/3599 [==============================] - 1s 212us/step - loss: 0.0332 - acc: 0.9859 - val_loss: 0.0486 - val_acc: 0.9801\n",
      "Epoch 42/120\n",
      "3599/3599 [==============================] - 1s 212us/step - loss: 0.0313 - acc: 0.9868 - val_loss: 0.0488 - val_acc: 0.9800\n",
      "Epoch 43/120\n",
      "3599/3599 [==============================] - 1s 219us/step - loss: 0.0305 - acc: 0.9873 - val_loss: 0.0454 - val_acc: 0.9818\n",
      "Epoch 44/120\n",
      "3599/3599 [==============================] - 1s 212us/step - loss: 0.0291 - acc: 0.9879 - val_loss: 0.0463 - val_acc: 0.9812\n",
      "Epoch 45/120\n",
      "3599/3599 [==============================] - 1s 217us/step - loss: 0.0288 - acc: 0.9878 - val_loss: 0.0463 - val_acc: 0.9816\n",
      "Epoch 46/120\n",
      "3599/3599 [==============================] - 1s 211us/step - loss: 0.0271 - acc: 0.9887 - val_loss: 0.0469 - val_acc: 0.9811\n",
      "Epoch 47/120\n",
      "3599/3599 [==============================] - 1s 217us/step - loss: 0.0259 - acc: 0.9893 - val_loss: 0.0445 - val_acc: 0.9821\n",
      "Epoch 48/120\n",
      "3599/3599 [==============================] - 1s 215us/step - loss: 0.0261 - acc: 0.9891 - val_loss: 0.0455 - val_acc: 0.9816\n",
      "Epoch 49/120\n",
      "3599/3599 [==============================] - 1s 216us/step - loss: 0.0243 - acc: 0.9901 - val_loss: 0.0435 - val_acc: 0.9833\n",
      "Epoch 50/120\n",
      "3599/3599 [==============================] - 1s 216us/step - loss: 0.0236 - acc: 0.9902 - val_loss: 0.0443 - val_acc: 0.9826\n",
      "Epoch 51/120\n",
      "3599/3599 [==============================] - 1s 214us/step - loss: 0.0234 - acc: 0.9904 - val_loss: 0.0433 - val_acc: 0.9830\n",
      "Epoch 52/120\n",
      "3599/3599 [==============================] - 1s 216us/step - loss: 0.0216 - acc: 0.9913 - val_loss: 0.0413 - val_acc: 0.9842\n",
      "Epoch 53/120\n",
      "3599/3599 [==============================] - 1s 217us/step - loss: 0.0208 - acc: 0.9916 - val_loss: 0.0448 - val_acc: 0.9826\n",
      "Epoch 54/120\n",
      "2560/3599 [====================>.........] - ETA: 0s - loss: 0.0214 - acc: 0.9912"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(np.array(df_train[\"in\"].values.tolist()), np.array(df_train[\"out\"].values.tolist()), epochs=120, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model3, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_p120 = evaluate_algorisms(model3, df_test)\n",
    "df3_p120.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Certin!!!\n",
    "Encontrar os parâmetros ótimos para cada problema é um processo iterativo e requer paciência e experiência.\n",
    "\n",
    "## Importante\n",
    "- Cada \"neurônio\" é muito simples (MatMul, Bias Add, ACTIVATE!);\n",
    "- Backpropagation;\n",
    "- Escolha da arquitetura e hiperparâmetros (camadas, ativações, otimizador);\n",
    "- **Escolha do custo**;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(n):\n",
    "    n_enc = encode_in(n)\n",
    "    print(\"encode n: {}\".format(n_enc))\n",
    "    pred = model3.predict(np.array([n_enc]))\n",
    "    print(\"pred enc_n: {}\".format(pred.round(3).reshape((16, -1))))\n",
    "    out = decode_out(pred)\n",
    "    print(\"decode pred: {}\".format(out))\n",
    "    return out\n",
    "predict(666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shhhh 🤫 Último modelo\n",
    "\n",
    "Conhecimento de domínio pode auxiliar muito no treinamento dos modelos. Sabendo que a base dos algorítmos romanos é decimal, podemos passar os dígitos de entrada com um `encoding` decimal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_in(row):\n",
    "    zeros = np.zeros((4, 10)).astype(np.uint8)\n",
    "    R = [int(c) for c in str(row).zfill(4)]\n",
    "    zeros[np.arange(4), R] = 1\n",
    "    return zeros.flatten()\n",
    "\n",
    "df[\"in\"] = df[\"numero\"].apply(encode_in)\n",
    "df[\"in\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_in(row):\n",
    "    return int(\"\".join([str(np.argmax(line)) for line in row.reshape(4, 10)]))\n",
    "\n",
    "df[\"in\"].apply(decode_in)\n",
    "df[\"in\"].apply(decode_in) == df[\"numero\"]\n",
    "all(df[\"in\"].apply(decode_in) == df[\"numero\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.6)\n",
    "df_train = df_train.reset_index().drop(columns=\"index\")\n",
    "df_test = df_test.reset_index().drop(columns=\"index\")\n",
    "print(\"treino:\", len(df_train), \"teste:\", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(units=64, activation='relu', input_dim=40))\n",
    "model4.add(Dense(units=128, activation='sigmoid'))\n",
    "model4.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.01\n",
    "                             , beta_1=0.5, beta_2=0.9),\n",
    "              metrics=['accuracy'])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = model4.fit(np.array(df_train[\"in\"].values.tolist()), np.array(df_train[\"out\"].values.tolist()), epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model4, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_p50 = evaluate_algorisms(model4, df_test)\n",
    "df4_p50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "### - Algarismos Romanos + NN = EZ\n",
    "### - ML is FUN kids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
